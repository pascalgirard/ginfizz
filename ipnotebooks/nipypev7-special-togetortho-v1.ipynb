{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plus slice timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.rapidart as ra      # artifact detection\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "import os                                    # system functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm_standalone='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/run_spm12.sh'\n",
    "mcr='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import spm\n",
    "\n",
    "# essai du mercredi soir matlab_cmd = ' '.join([spm_standalone,mcr,'batch','script'])\n",
    "matlab_cmd = ' '.join([spm_standalone,mcr,'batch'])\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype\n",
    "# Optional: Use the following lines to increase verbosity of output\n",
    "nipype.config.set('logging', 'workflow_level',  'INFO')\n",
    "nipype.config.set('logging', 'interface_level', 'INFO')\n",
    "nipype.logging.update_logging(nipype.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - we decode the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flibasedir = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we get the xml file in this directory\n",
    "def getXmlFile(flibasedir):\n",
    "    import os\n",
    "    dirs = os.listdir( flibasedir )\n",
    "    #print dirs\n",
    "\n",
    "    import re\n",
    "    xmlmatch = r'(.*)xml'\n",
    "    for dir in dirs:\n",
    "        xmlfound=re.search(xmlmatch,dir,flags=0)\n",
    "        if xmlfound:\n",
    "            #print xmlfound.group()\n",
    "            return flibasedir + '/' + xmlfound.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/xml_example.xml\n"
     ]
    }
   ],
   "source": [
    "xmlfile = getXmlFile(flibasedir)\n",
    "\n",
    "print xmlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the we decode the xmlfile\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xmlfile)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS_analysis\n"
     ]
    }
   ],
   "source": [
    "print root.tag\n",
    "\n",
    "def getEpiInfos(xmlfile):\n",
    "    result = {}\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # epibold directory\n",
    "        for epibold in root.iter('EPIBOLD'):\n",
    "            for child in epibold:\n",
    "                print child.text\n",
    "                if child.tag == 'file':\n",
    "                    epidir = child.text\n",
    "                    result['epidir'] = epidir\n",
    "                    print epidir\n",
    "                    \n",
    "                # parameters\n",
    "                if child.tag == 'parameters':\n",
    "                    print \"parameters\"\n",
    "                    \n",
    "                    for child2 in child:\n",
    "                                                     \n",
    "                        # TR\n",
    "                        if child2.tag == 'TR':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    tr = child3.text\n",
    "                                    print tr\n",
    "                                    result['TR'] = tr\n",
    "                    \n",
    "                        # dynamics\n",
    "                        if child2.tag == 'dynamics':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    dynamics = child3.text\n",
    "                                    result['dynamics'] = dynamics\n",
    "                                    \n",
    "                        # sliceTimingVector\n",
    "                        if child2.tag == 'sliceTimingVector':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    sliceTimingVector = child3.text\n",
    "                                    result['sliceTimingVector'] = sliceTimingVector\n",
    "                                    \n",
    "                        # nb_slices\n",
    "                        if child2.tag == 'nb_slices':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    nb_slices = child3.text\n",
    "                                    result['nb_slices'] = nb_slices\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        print 'exception'\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n",
      "{'sliceTimingVector': '1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30', 'dynamics': '240', 'nb_slices': '31', 'TR': '2', 'epidir': '/EPIBOLD/'}\n"
     ]
    }
   ],
   "source": [
    "epiResults = getEpiInfos(xmlfile)\n",
    "print epiResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getT1file(xmlfile):\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # T1 directory and file\n",
    "        for t1 in root.iter('T1'):\n",
    "            for child in t1:\n",
    "                #print child.text\n",
    "                if child.tag == 'file':\n",
    "                    t1 = child.text\n",
    "                    t1 = flibasedir + t1\n",
    "                    # print  t1\n",
    "    except:\n",
    "        print 'exception'\n",
    "    return t1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/T1/t0009_t1_s03.nii\n"
     ]
    }
   ],
   "source": [
    "t1 = getT1file(xmlfile)\n",
    "print t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pileline declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - first node data grabbing by select files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T1': <undefined>, 'epi': <undefined>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epidir = getEpiInfos(xmlfile)['epidir']\n",
    "epidir = flibasedir + epidir\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(T1=t1,\n",
    "                 epi= epidir + \"/\" + \"*.nii\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - segment T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment = pe.Node(interface=spm.NewSegment(), name='segment')\n",
    "\n",
    "#seg.inputs.channel_files = 't0009_t1_s03.nii'\n",
    "segment.inputs.channel_info =(0.001,60.0,(True,True))          \n",
    "segment.inputs.sampling_distance= 3.0\n",
    "# todo donner un chemin de TPM.nii comme argument de la future fct\n",
    "tissue1 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 1), 1, (True,False), (False, False))\n",
    "tissue2 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 2), 1, (True,False), (False, False))\n",
    "tissue3 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 3), 2, (True,False), (False, False))\n",
    "tissue4 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 4), 3, (True,False), (False, False))\n",
    "tissue5 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 5), 4, (True,False), (False, False))\n",
    "tissue6 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 6), 2, (False,False), (False, False))\n",
    "segment.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "segment.inputs.affine_regularization = 'mni'\n",
    "#segment.inputs.warping_regularization = [0.0, 0.001, 0.5, 0.05, 0.2]\n",
    "segment.inputs.write_deformation_fields = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - slice timing of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "st = pe.Node(interface=spm.SliceTiming(), name='st')\n",
    "#st.inputs.in_files = 'functional.nii'\n",
    "st.inputs.num_slices = int(epiResults['nb_slices'])\n",
    "st.inputs.time_repetition = float(epiResults['TR'])\n",
    "st.inputs.time_acquisition = float(epiResults['TR']) - float(epiResults['TR'])/2.0\n",
    "st.inputs.slice_order = lint\n",
    "st.inputs.ref_slice = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - realign of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realign = pe.Node(interface=spm.Realign(), name='realign')\n",
    "\n",
    "realign.inputs.register_to_mean = False\n",
    "realign.inputs.quality = 0.9\n",
    "realign.inputs.separation = 4\n",
    "realign.inputs.fwhm = 5\n",
    "realign.inputs.interp = 2\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "# essai au defaut 2, 1 realign.inputs.write_which = [0, 1]\n",
    "realign.inputs.write_which = [0, 1]\n",
    "realign.inputs.write_interp = 4\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "realign.inputs.write_mask = True\n",
    "realign.inputs.out_prefix = 'r'\n",
    "realign.inputs.jobtype = 'estwrite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Coregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 -fsl merge\n",
    "fsl_merge = Node(Function(input_names=['in_files', 'tr', 'force_even', 'sort'], \n",
    "                          output_names=['merged_file'],                               \n",
    "                          function=bigMerge), name=\"fsl_merge\")     \n",
    "fsl_merge.plugin_args = {'qsub_args':'-l h_vmem=30G',  'sbatch_args':'--mem-per-cpu 30000'} \n",
    "from nipype doc:\n",
    ">>> from nipype.interfaces.fsl import Merge\n",
    ">>> merger = Merge()\n",
    ">>> merger.inputs.in_files = ['functional2.nii', 'functional3.nii']\n",
    ">>> merger.inputs.dimension = 't'\n",
    ">>> merger.inputs.output_type = 'NIFTI_GZ'\n",
    ">>> merger.cmdline \n",
    "'fslmerge -t functional2_merged.nii.gz functional2.nii functional3.nii'\n",
    ">>> merger.inputs.tr = 2.25\n",
    ">>> merger.cmdline \n",
    "'fslmerge -tr functional2_merged.nii.gz functional2.nii functional3.nii 2.25'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import Merge\n",
    "fsl_merge = pe.Node(interface=Merge(), name=\"fsl_merge\")     \n",
    " \n",
    "fsl_merge.inputs.dimension = 't'\n",
    "fsl_merge.inputs.output_type = 'NIFTI_GZ'\n",
    "fsl_merge.inputs.tr = 2.0\n",
    "#fsl_merge.inputs.force_even = False     \n",
    "fsl_merge.inputs.ignore_exception = False     \n",
    "#fsl_merge.inputs.sort = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - low pass high pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import afni\n",
    "\n",
    "bandpass = pe.Node(interface=afni.Bandpass(), name='bandpass')\n",
    "# bandpass.inputs.in_file = 'functional.nii'\n",
    "\n",
    "bandpass.inputs.highpass = 0.005\n",
    "bandpass.inputs.lowpass = 0.2\n",
    "bandpass.inputs.automask = False     \n",
    "bandpass.inputs.environ = {}\n",
    "bandpass.inputs.outputtype = 'NIFTI_GZ'     \n",
    "bandpass.inputs.terminal_output = 'stream'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connection du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect(filesource,\"T1\" ,segment, 'channel_files')\n",
    "\n",
    "preproc.connect(filesource,\"epi\" ,st, 'in_files')\n",
    "\n",
    "preproc.connect(st,\"timecorrected_files\" ,realign, 'in_files')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the results in the datasink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment results\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n",
    "preproc.connect(segment,  'bias_field_images' , datasink, 'structural.@par1')\n",
    "preproc.connect(segment,  'forward_deformation_field' , datasink, 'structural.@par2')\n",
    "preproc.connect(segment,  'inverse_deformation_field' , datasink, 'structural.@par3')\n",
    "preproc.connect(segment,  'modulated_class_images' , datasink, 'structural.@par4')\n",
    "preproc.connect(segment,  'native_class_images' , datasink, 'structural.@par5')\n",
    "preproc.connect(segment,  'transformation_mat' , datasink, 'structural.@par6')\n",
    "preproc.connect(segment,  'dartel_input_images' , datasink, 'structural.@par7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice timing results\n",
    "preproc.connect(st,  'timecorrected_files', datasink, 'functionnal')\n",
    "\n",
    "# realign mean_image and realignment_parameters\n",
    "preproc.connect(realign,  'mean_image', datasink, 'functionnal.@par')\n",
    "preproc.connect(realign,  'realignment_parameters', datasink, 'functionnal.@par1')\n",
    "preproc.connect(realign,  'realigned_files', datasink, 'functionnal.@par2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmppcQwty/preproc/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node segment in dir: /tmp/tmp2UT9SF/preproc/segment\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node st in dir: /tmp/tmpfu3eIl/preproc/st\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node realign in dir: /tmp/tmpImYh4L/preproc/realign\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node datasink in dir: /tmp/tmpKhSADT/preproc/datasink\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f9c0c7b1c10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().help()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.tsa.arima_model.ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "afni.Bandpass().help()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels import  tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm\n",
    "\n",
    ".Normalize12().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Coregister.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(epiResults['TR']) - float(epiResults['TR'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_corrected_images = <undefined>\n",
    "bias_field_images = <undefined>\n",
    "dartel_input_images = <undefined>\n",
    "forward_deformation_field = <undefined>\n",
    "inverse_deformation_field = <undefined>\n",
    "modulated_class_images = <undefined>\n",
    "native_class_images = <undefined>\n",
    "normalized_class_images = <undefined>\n",
    "transformation_mat = <undefined>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.output_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd /homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/EPIBOLD\n",
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
