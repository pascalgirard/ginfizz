{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "de v1 à v2 on introduit les masks wm et lcf et les meants\n",
    "de v2 à v3 on plot les mocos, on wrappe le code python, on wrappe le code mathlab bramilla. on refait tout le pipeline\n",
    "de v3 à v4 on change les premier et dernier noeud en identity interfacepour se brancher direct sur le proprocess pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To calculate parameters for afni bandpass function and write them in ortho file.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of the new subworkflow - PREBANDPASS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# rp_at0009_epi_s04_d0001.txt\n",
    "# todo recuperer le seul fichier texte de results functionnal\n",
    "# rp_at0009_epi_s+04_d0001.txt\n",
    "\n",
    "mocoFile = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "from nipype.interfaces.fsl.utils import PlotMotionParams   # to plot moco variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creation of a subworflow to calculate the bandpass parameters\n",
    "prebandpass = pe.Workflow(name='prebandpass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lcfMask': <undefined>,\n",
       " 'mergedFile': <undefined>,\n",
       " 'mocoVariables': <undefined>,\n",
       " 'wmMask': <undefined>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo remplace this node by an identity node that get input from preprocess pipeline / node 7 eg. fsl merge\n",
    "# input node get the good files first the tissues normalised files\n",
    "sourcedir = '/homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files'\n",
    "# second the merged functionnal file\n",
    "sourcemergeddir = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal'\n",
    "\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(wmMask=sourcedir+ \"/\" + \"wc2*.nii\",\n",
    "                 lcfMask=sourcedir+ \"/\" + \"wc3*.nii\",\n",
    "                 mergedFile=sourcemergeddir+ \"/\" + \"*_merged.nii.gz\",\n",
    "                 mocoVariables=sourcemergeddir+ \"/\" + \"rp*.txt\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - compute moco file to feed with ortho.txt file the bandpass node of preprocess workflow "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "derivatives\n",
    "lets assume that the time of acquisition between 2 mesures is TR = 2 000 ms\n",
    "dx(t)= x(t+1) - x(t-1) / 2 * TR\n",
    "x(t0) = x(t1)\n",
    "acqNb = 240\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node 1 - compute moco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def computeMoco(mocoFile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "\n",
    "    # read the moco file to put it in a panda dataframe \n",
    "    mocodf = pd.read_csv(mocoFile, header=None, sep='  ',engine='python')\n",
    "    print(mocodf.head())\n",
    "    # todo recuperer ces infos de l'autre pipeline\n",
    "    TR = 2000 \n",
    "    acqNb = 240\n",
    "\n",
    "    def vectorDerivative(v):\n",
    "        dv = {}\n",
    "        for i in range(acqNb):\n",
    "            # print mocodf['x'][i]\n",
    "            if i== 0:\n",
    "                dv[i]= (v[i+1]-v[i]) / 2*TR\n",
    "            elif i== acqNb-1:\n",
    "                dv[i]= (v[i]-v[i-1]) / 2*TR \n",
    "            else:\n",
    "                dv[i]= (v[i+1]-v[i-1]) / 2*TR\n",
    "                #print 'derivative' + str(i)\n",
    "                #print  v[i]\n",
    "        return v\n",
    "\n",
    "    def plusDerivative(df):\n",
    "        lg = len(df.columns.values)\n",
    "        dg = df\n",
    "        for j in list(df.columns.values):\n",
    "            vprime = vectorDerivative(df[j])\n",
    "            dg[lg+j]=vprime\n",
    "        return dg\n",
    "    \n",
    "    def plusSquare(df):\n",
    "        lg = len(df.columns.values)\n",
    "        ds = df\n",
    "        for j in list(df.columns.values):\n",
    "            vs = df[j]**2\n",
    "            ds[lg+j]=vs\n",
    "        return ds    \n",
    "\n",
    "    \n",
    "    # first, we derivate the 6 colunms of dataframe of moco file, and append the 6 new colums to df\n",
    "    dfderivate = plusDerivative(mocodf)\n",
    "    print(dfderivate.head())\n",
    "    \n",
    "    # then, we compute the square of the now 12 colums, and append them to df. it makes 24 colums that are going to \n",
    "    # participate in the ortho file to make 24 regressors bandpassed\n",
    "    dfsquare = plusSquare(dfderivate)\n",
    "    g = dfsquare.to_csv('ortho.txt', sep=' ', index=False,header=False)\n",
    "    print g\n",
    "    h = os.getcwd() + '/' + 'ortho.txt'\n",
    "    return h\n",
    "    \n",
    "\n",
    "computeMoco = Node(Function(input_names=['mocoFile'],\n",
    "                                output_names=['out_file'],\n",
    "                                function=computeMoco),\n",
    "                                name='computeMoco')\n",
    "\n",
    "\n",
    "\n",
    "prebandpass.connect(filesource, \"mocoVariables\", computeMoco, \"mocoFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 - Moco plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot moco variables\n",
    "MotionCorrectionPlot1 = Node(PlotMotionParams(), name=\"MotionCorrectionPlot1\")\n",
    "MotionCorrectionPlot1.inputs.ignore_exception = False     \n",
    "MotionCorrectionPlot1.inputs.in_source = 'spm'     \n",
    "MotionCorrectionPlot1.inputs.output_type = 'NIFTI_GZ'     \n",
    "MotionCorrectionPlot1.inputs.plot_size = (500, 1000)     \n",
    "MotionCorrectionPlot1.inputs.plot_type = 'rotations'     \n",
    "MotionCorrectionPlot1.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource, \"mocoVariables\", MotionCorrectionPlot1, \"in_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - get wm and lcf mask (normalised), erode them and calculate signal mean on both masks\n",
    "(input from segment + normalyse wmMask = '/homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc2t0009_t1_s03.nii')\n",
    "remark: erosion is done once; in connectomics, it is done 3 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate eroded binary mask for wm\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "\n",
    "erosion = pe.Node(interface=MathsCommand(), name='erosion')\n",
    "    \n",
    "erosion.inputs.args = '-thr 0 -uthr 111 -bin -ero  '     \n",
    "erosion.inputs.ignore_exception = False     \n",
    "erosion.inputs.output_type = 'NIFTI_GZ'     \n",
    "erosion.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"wmMask\" , erosion, \"in_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate eroded binary mask for lcf\n",
    "\n",
    "erosionLcf = pe.Node(interface=MathsCommand(), name='erosionLcf')\n",
    "    \n",
    "erosionLcf.inputs.args = '-thr 0 -uthr 111 -bin -ero '     \n",
    "erosionLcf.inputs.ignore_exception = False     \n",
    "erosionLcf.inputs.output_type = 'NIFTI_GZ'     \n",
    "erosionLcf.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"lcfMask\" , erosionLcf, \"in_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets calculate the mean signal on these eroded masks first on wm\n",
    "from nipype.interfaces.fsl.utils import ImageMeants\n",
    "\n",
    "wmMeants = Node(ImageMeants(), name=\"wmMeants\")     \n",
    "wmMeants.inputs.ignore_exception = False     \n",
    "wmMeants.inputs.order = 1     \n",
    "wmMeants.inputs.output_type = 'NIFTI_GZ'     \n",
    "wmMeants.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"mergedFile\" , wmMeants, \"in_file\")   \n",
    "prebandpass.connect(erosion, \"out_file\", wmMeants, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets calculate the mean signal on these eroded masks econd on lcf\n",
    "\n",
    "lcfMeants = Node(ImageMeants(), name=\"lcfMeants\")     \n",
    "lcfMeants.inputs.ignore_exception = False     \n",
    "lcfMeants.inputs.order = 1     \n",
    "lcfMeants.inputs.output_type = 'NIFTI_GZ'     \n",
    "wmMeants.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"mergedFile\" , lcfMeants, \"in_file\")   \n",
    "prebandpass.connect(erosionLcf, \"out_file\", lcfMeants, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets make an output node with the 3 files to be pass to afni bandpass: \n",
    "# file 1 with 24 colums moco, derivative moco, moco and derivative square\n",
    "# file 2 with wm mean signal on wm\n",
    "# file 3 with lcf mean signal on lcf\n",
    "\n",
    "field_list=['rotations_plot', \n",
    "            'moco_gradient_square',\n",
    "            'wm_normalized_eroded_mask',\n",
    "            'wm_meants',\n",
    "            'lcf_normalized_eroded_mask',\n",
    "            'lcf_meants']\n",
    "            \n",
    "            \n",
    "outputNode = Node(IdentityInterface(fields=field_list), name=\"outputNode\")\n",
    "\n",
    "# for plot files\n",
    "prebandpass.connect(MotionCorrectionPlot1,  'out_file', outputNode, 'rotations_plot')\n",
    "\n",
    "# for moco , gradient and square\n",
    "prebandpass.connect(computeMoco,  'out_file', outputNode, 'moco_gradient_square')\n",
    "\n",
    "# for segmented normalised eroded wm and lcf mask\n",
    "prebandpass.connect(erosion,  'out_file', outputNode, 'wm_normalized_eroded_mask')\n",
    "prebandpass.connect(erosionLcf,  'out_file', outputNode, 'lcf_normalized_eroded_mask')\n",
    "\n",
    "# for wm and lcf mean signal to text files in functionnal repository\n",
    "prebandpass.connect(wmMeants,  'out_file', outputNode, 'wm_meants')\n",
    "prebandpass.connect(lcfMeants,  'out_file', outputNode, 'lcf_meants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmpMf0kit/prebandpass/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node erosionLcf in dir: /tmp/tmpAt4rBF/prebandpass/erosionLcf\n",
      "INFO:workflow:Running: fslmaths /homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc3t0009_t1_s03.nii -thr 0 -uthr 111 -bin -ero  /tmp/tmpAt4rBF/prebandpass/erosionLcf/wc3t0009_t1_s03_maths.nii.gz\n",
      "INFO:workflow:Executing node lcfMeants in dir: /tmp/tmprYOb3t/prebandpass/lcfMeants\n",
      "INFO:workflow:Running: fslmeants -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/wcrat0009_epi_s04_d0001_merged.nii.gz -m /tmp/tmpAt4rBF/prebandpass/erosionLcf/wc3t0009_t1_s03_maths.nii.gz --order=1 -o /tmp/tmprYOb3t/prebandpass/lcfMeants/wcrat0009_epi_s04_d0001_merged_ts.txt\n",
      "INFO:workflow:Executing node MotionCorrectionPlot1 in dir: /tmp/tmp5ZhlGc/prebandpass/MotionCorrectionPlot1\n",
      "INFO:workflow:Running: fsl_tsplot -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt -o /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001_rot.png -h 500 -w 1000 -t 'Realign estimated rotations (radians)' --start=4 --finish=6 -a x,y,z\n",
      "INFO:workflow:Executing node erosion in dir: /tmp/tmpsVR7vb/prebandpass/erosion\n",
      "INFO:workflow:Running: fslmaths /homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc2t0009_t1_s03.nii -thr 0 -uthr 111 -bin -ero   /tmp/tmpsVR7vb/prebandpass/erosion/wc2t0009_t1_s03_maths.nii.gz\n",
      "INFO:workflow:Executing node wmMeants in dir: /tmp/tmpikl_PG/prebandpass/wmMeants\n",
      "INFO:workflow:Running: fslmeants -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/wcrat0009_epi_s04_d0001_merged.nii.gz -m /tmp/tmpsVR7vb/prebandpass/erosion/wc2t0009_t1_s03_maths.nii.gz --order=1 -o /tmp/tmpikl_PG/prebandpass/wmMeants/wcrat0009_epi_s04_d0001_merged_ts.txt\n",
      "INFO:workflow:Executing node computeMoco in dir: /tmp/tmpXjDCTO/prebandpass/computeMoco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1             2         3             4  \\\n",
      "0  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000  2.848359e-35   \n",
      "1  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305 -5.038878e-05   \n",
      "2  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359 -5.419149e-05   \n",
      "3  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042  1.485895e-05   \n",
      "4  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036  8.939434e-05   \n",
      "\n",
      "              5  \n",
      "0  2.768145e-18  \n",
      "1  3.284350e-05  \n",
      "2  1.160633e-04  \n",
      "3 -5.470219e-06  \n",
      "4 -1.247659e-04  \n",
      "             0             1             2         3             4   \\\n",
      "0  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000  2.848359e-35   \n",
      "1  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305 -5.038878e-05   \n",
      "2  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359 -5.419149e-05   \n",
      "3  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042  1.485895e-05   \n",
      "4  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036  8.939434e-05   \n",
      "\n",
      "             5             6             7             8         9   \\\n",
      "0  2.768145e-18  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000   \n",
      "1  3.284350e-05  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305   \n",
      "2  1.160633e-04  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359   \n",
      "3 -5.470219e-06  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042   \n",
      "4 -1.247659e-04  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036   \n",
      "\n",
      "             10            11  \n",
      "0  2.848359e-35  2.768145e-18  \n",
      "1 -5.038878e-05  3.284350e-05  \n",
      "2 -5.419149e-05  1.160633e-04  \n",
      "3  1.485895e-05 -5.470219e-06  \n",
      "4  8.939434e-05 -1.247659e-04  \n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fc130f59c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the run\n",
    "prebandpass.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of precalculations dump in ortho.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data sink\n",
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'\n",
    "\n",
    "# for plot files\n",
    "prebandpass.connect(MotionCorrectionPlot1,  'out_file', datasink, '.plotfiles')\n",
    "\n",
    "# for segmented normalised eroded wm and lcf mask\n",
    "prebandpass.connect(erosion,  'out_file', datasink, 'functionnal.bandpass_wm_mask')\n",
    "prebandpass.connect(erosionLcf,  'out_file', datasink, 'functionnal.bandpass_lcf_mask')\n",
    "\n",
    "# for wm and lcf mean signal to text files in functionnal repository\n",
    "prebandpass.connect(wmMeants,  'out_file', datasink, 'functionnal.bandpass_wm_meants')\n",
    "prebandpass.connect(lcfMeants,  'out_file', datasink, 'functionnal.bandpass_lcf_meants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mocoFile = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeMoco.inputs.mocoFile=mocoFile\n",
    "res = computeMoco(mocoFile).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def mocoOrtho(f):\n",
    "    df = pd.read_csv(f, header=None, sep='  ',engine='python')\n",
    "    dfd = plusDerivative(df)\n",
    "    dfs = plusSquare(dfd)\n",
    "    g = dfs.to_csv('ortho.txt', sep=' ', index=False,header=False)\n",
    "    print g\n",
    "    h = os.getcwd() + '/' + 'ortho.txt'\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mocoOrtho('/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ImageMeants().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Node: fsconv.editWmMask     \n",
    "editWmMask = Node(MathsCommand(), name=\"editWmMask\")     \n",
    "editWmMask.inputs.args = '-thr 0 -uthr 111 -bin -ero -ero -ero '     \n",
    "editWmMask.inputs.ignore_exception = False     \n",
    "editWmMask.inputs.output_type = 'NIFTI_GZ'     \n",
    "editWmMask.inputs.terminal_output = 'stream'     \n",
    "fsconv.connect(fsWm2Nii, \"out_file\", editWmMask, \"in_file\")\n",
    "\n",
    "from web\n",
    "##############################################################################################\n",
    "##erode a mask or image by zeroing non-zero voxels when zero voxels found in kernel\n",
    "##############################################################################################\n",
    "fslmaths 'mask.nii.gz' -kernel box 5x5x5 -ero 'output_image.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "square = plusSquare(derivate)\n",
    "print(square.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorSquare(mocodf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(mocodf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorderivative(mocodf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TR = 2000 \n",
    "acqNb = 240\n",
    "\n",
    "dx = {}\n",
    "for i in range(acqNb):\n",
    "    # print mocodf['x'][i]\n",
    "    if i== 0:\n",
    "        dx[i]= (mocodf['x'][i+1]-mocodf['x'][i]) / 2*TR\n",
    "    elif i== acqNb-1:\n",
    "        dx[i]= (mocodf['x'][i]-mocodf['x'][i-1]) / 2*TR \n",
    "    else:\n",
    "        dx[i]= (mocodf['x'][i+1]-mocodf['x'][i-1]) / 2*TR\n",
    "    print 'derivative' + str(i)\n",
    "    print  dx[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdx = pd.Series(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
