{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "de v1 à v2 on introduit les masks wm et lcf et les meants\n",
    "de v2 à v3 on plot les mocos, on wrappe le code python, on wrappe le code mathlab bramilla. on refait tout le pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To calculate parameters for afni bandpass function and write them in ortho file.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of the new subworkflow - PREBANDPASS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# rp_at0009_epi_s04_d0001.txt\n",
    "# todo recuperer le seul fichier texte de results functionnal\n",
    "# rp_at0009_epi_s+04_d0001.txt\n",
    "\n",
    "mocoFile = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "from nipype.interfaces.fsl.utils import PlotMotionParams   # to plot moco variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creation of a subworflow to calculate the bandpass parameters\n",
    "prebandpass = pe.Workflow(name='prebandpass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lcfMask': <undefined>,\n",
       " 'mergedFile': <undefined>,\n",
       " 'mocoVariables': <undefined>,\n",
       " 'wmMask': <undefined>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo remplace this node by an identity node that get input from preprocess pipeline / node 7 eg. fsl merge\n",
    "# input node get the good files first the tissues normalised files\n",
    "sourcedir = '/homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files'\n",
    "# second the merged functionnal file\n",
    "sourcemergeddir = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal'\n",
    "\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(wmMask=sourcedir+ \"/\" + \"wc2*.nii\",\n",
    "                 lcfMask=sourcedir+ \"/\" + \"wc3*.nii\",\n",
    "                 mergedFile=sourcemergeddir+ \"/\" + \"*_merged.nii.gz\",\n",
    "                 mocoVariables=sourcemergeddir+ \"/\" + \"rp*.txt\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - compute moco file to feed with ortho.txt file the bandpass node of preprocess workflow "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "derivatives\n",
    "lets assume that the time of acquisition between 2 mesures is TR = 2 000 ms\n",
    "dx(t)= x(t+1) - x(t-1) / 2 * TR\n",
    "x(t0) = x(t1)\n",
    "acqNb = 240\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node 1 - compute moco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function\n",
    "\n",
    "def computeMoco(mocoFile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "\n",
    "    # read the moco file to put it in a panda dataframe \n",
    "    mocodf = pd.read_csv(mocoFile, header=None, sep='  ',engine='python')\n",
    "    print(mocodf.head())\n",
    "    # todo recuperer ces infos de l'autre pipeline\n",
    "    TR = 2000 \n",
    "    acqNb = 240\n",
    "\n",
    "    def vectorDerivative(v):\n",
    "        dv = {}\n",
    "        for i in range(acqNb):\n",
    "            # print mocodf['x'][i]\n",
    "            if i== 0:\n",
    "                dv[i]= (v[i+1]-v[i]) / 2*TR\n",
    "            elif i== acqNb-1:\n",
    "                dv[i]= (v[i]-v[i-1]) / 2*TR \n",
    "            else:\n",
    "                dv[i]= (v[i+1]-v[i-1]) / 2*TR\n",
    "                #print 'derivative' + str(i)\n",
    "                #print  v[i]\n",
    "        return v\n",
    "\n",
    "    def plusDerivative(df):\n",
    "        lg = len(df.columns.values)\n",
    "        dg = df\n",
    "        for j in list(df.columns.values):\n",
    "            vprime = vectorDerivative(df[j])\n",
    "            dg[lg+j]=vprime\n",
    "        return dg\n",
    "    \n",
    "    def plusSquare(df):\n",
    "        lg = len(df.columns.values)\n",
    "        ds = df\n",
    "        for j in list(df.columns.values):\n",
    "            vs = df[j]**2\n",
    "            ds[lg+j]=vs\n",
    "        return ds    \n",
    "\n",
    "    \n",
    "    # first, we derivate the 6 colunms of dataframe of moco file, and append the 6 new colums to df\n",
    "    dfderivate = plusDerivative(mocodf)\n",
    "    print(dfderivate.head())\n",
    "    \n",
    "    # then, we compute the square of the now 12 colums, and append them to df. it makes 24 colums that are going to \n",
    "    # participate in the ortho file to make 24 regressors bandpassed\n",
    "    dfsquare = plusSquare(dfderivate)\n",
    "    g = dfsquare.to_csv('ortho.txt', sep=' ', index=False,header=False)\n",
    "    print g\n",
    "    h = os.getcwd() + '/' + 'ortho.txt'\n",
    "    return h\n",
    "    \n",
    "\n",
    "computeMoco = Node(Function(input_names=['mocoFile'],\n",
    "                                output_names=['out_file'],\n",
    "                                function=computeMoco),\n",
    "                                name='computeMoco')\n",
    "\n",
    "\n",
    "\n",
    "prebandpass.connect(filesource, \"mocoVariables\", computeMoco, \"mocoFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - get wm mask (normalised) and calculate signal mean\n",
    "input from segment + normalyse wmMask = '/homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc2t0009_t1_s03.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot moco variables\n",
    "MotionCorrectionPlot1 = Node(PlotMotionParams(), name=\"MotionCorrectionPlot1\")\n",
    "MotionCorrectionPlot1.inputs.ignore_exception = False     \n",
    "MotionCorrectionPlot1.inputs.in_source = 'spm'     \n",
    "MotionCorrectionPlot1.inputs.output_type = 'NIFTI_GZ'     \n",
    "MotionCorrectionPlot1.inputs.plot_size = (500, 1000)     \n",
    "MotionCorrectionPlot1.inputs.plot_type = 'rotations'     \n",
    "MotionCorrectionPlot1.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource, \"mocoVariables\", MotionCorrectionPlot1, \"in_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate eroded binary mask for wm\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "\n",
    "erosion = pe.Node(interface=MathsCommand(), name='erosion')\n",
    "    \n",
    "erosion.inputs.args = '-thr 0 -uthr 111 -bin -ero  '     \n",
    "erosion.inputs.ignore_exception = False     \n",
    "erosion.inputs.output_type = 'NIFTI_GZ'     \n",
    "erosion.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"wmMask\" , erosion, \"in_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate eroded binary mask for lcf\n",
    "\n",
    "erosionLcf = pe.Node(interface=MathsCommand(), name='erosionLcf')\n",
    "    \n",
    "erosionLcf.inputs.args = '-thr 0 -uthr 111 -bin -ero '     \n",
    "erosionLcf.inputs.ignore_exception = False     \n",
    "erosionLcf.inputs.output_type = 'NIFTI_GZ'     \n",
    "erosionLcf.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"lcfMask\" , erosionLcf, \"in_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets calculate the mean signal on these eroded masks first on wm\n",
    "from nipype.interfaces.fsl.utils import ImageMeants\n",
    "\n",
    "wmMeants = Node(ImageMeants(), name=\"wmMeants\")     \n",
    "wmMeants.inputs.ignore_exception = False     \n",
    "wmMeants.inputs.order = 1     \n",
    "wmMeants.inputs.output_type = 'NIFTI_GZ'     \n",
    "wmMeants.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"mergedFile\" , wmMeants, \"in_file\")   \n",
    "prebandpass.connect(erosion, \"out_file\", wmMeants, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets calculate the mean signal on these eroded masks econd on lcf\n",
    "\n",
    "lcfMeants = Node(ImageMeants(), name=\"lcfMeants\")     \n",
    "lcfMeants.inputs.ignore_exception = False     \n",
    "lcfMeants.inputs.order = 1     \n",
    "lcfMeants.inputs.output_type = 'NIFTI_GZ'     \n",
    "wmMeants.inputs.terminal_output = 'stream'     \n",
    "prebandpass.connect(filesource,\"mergedFile\" , lcfMeants, \"in_file\")   \n",
    "prebandpass.connect(erosionLcf, \"out_file\", lcfMeants, \"mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data sink\n",
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'\n",
    "\n",
    "# for plot files\n",
    "prebandpass.connect(MotionCorrectionPlot1,  'out_file', datasink, '.plotfiles')\n",
    "\n",
    "# for segmented normalised eroded wm and lcf mask\n",
    "prebandpass.connect(erosion,  'out_file', datasink, 'functionnal.bandpass_wm_mask')\n",
    "prebandpass.connect(erosionLcf,  'out_file', datasink, 'functionnal.bandpass_lcf_mask')\n",
    "\n",
    "# for wm and lcf mean signal to text files in functionnal repository\n",
    "prebandpass.connect(wmMeants,  'out_file', datasink, 'functionnal.bandpass_wm_meants')\n",
    "prebandpass.connect(lcfMeants,  'out_file', datasink, 'functionnal.bandpass_lcf_meants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmpRF0qmX/prebandpass/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node erosionLcf in dir: /tmp/tmpo4ekf_/prebandpass/erosionLcf\n",
      "INFO:workflow:Running: fslmaths /homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc3t0009_t1_s03.nii -thr 0 -uthr 111 -bin -ero  /tmp/tmpo4ekf_/prebandpass/erosionLcf/wc3t0009_t1_s03_maths.nii.gz\n",
      "INFO:workflow:Executing node computeMoco in dir: /tmp/tmperagor/prebandpass/computeMoco\n",
      "INFO:workflow:Executing node MotionCorrectionPlot1 in dir: /tmp/tmp5SYylV/prebandpass/MotionCorrectionPlot1\n",
      "INFO:workflow:Running: fsl_tsplot -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt -o /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001_rot.png -h 500 -w 1000 -t 'Realign estimated rotations (radians)' --start=4 --finish=6 -a x,y,z\n",
      "INFO:workflow:Executing node erosion in dir: /tmp/tmpwKU6Bx/prebandpass/erosion\n",
      "INFO:workflow:Running: fslmaths /homes_unix/hirsch/_pypipe/datadir/data_results/structural/norm_files/wc2t0009_t1_s03.nii -thr 0 -uthr 111 -bin -ero   /tmp/tmpwKU6Bx/prebandpass/erosion/wc2t0009_t1_s03_maths.nii.gz\n",
      "INFO:workflow:Executing node wmMeants in dir: /tmp/tmpFcaHBo/prebandpass/wmMeants\n",
      "INFO:workflow:Running: fslmeants -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/wcrat0009_epi_s04_d0001_merged.nii.gz -m /tmp/tmpwKU6Bx/prebandpass/erosion/wc2t0009_t1_s03_maths.nii.gz --order=1 -o /tmp/tmpFcaHBo/prebandpass/wmMeants/wcrat0009_epi_s04_d0001_merged_ts.txt\n",
      "INFO:workflow:Executing node lcfMeants in dir: /tmp/tmpvAbg_M/prebandpass/lcfMeants\n",
      "INFO:workflow:Running: fslmeants -i /homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/wcrat0009_epi_s04_d0001_merged.nii.gz -m /tmp/tmpo4ekf_/prebandpass/erosionLcf/wc3t0009_t1_s03_maths.nii.gz --order=1 -o /tmp/tmpvAbg_M/prebandpass/lcfMeants/wcrat0009_epi_s04_d0001_merged_ts.txt\n",
      "INFO:workflow:Executing node datasink in dir: /tmp/tmpSy1ZmX/prebandpass/datasink\n",
      "ERROR:workflow:['Node datasink failed to run on host pipeau.dgin.bor.']\n",
      "INFO:workflow:Saving crash info to /homes_unix/hirsch/_ipnotebooks/crash-20170317-121740-hirsch-datasink-0b512184-2feb-44ee-af60-2ea1586d77e9.pklz\n",
      "INFO:workflow:Traceback (most recent call last):\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 39, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 394, in run\n",
      "    self._run_interface()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 504, in _run_interface\n",
      "    self._result = self._run_command(execute)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 630, in _run_command\n",
      "    result = self._interface.run()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1035, in run\n",
      "    outputs = self.aggregate_outputs(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1106, in aggregate_outputs\n",
      "    predicted_outputs = self._list_outputs()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/io.py\", line 711, in _list_outputs\n",
      "    if d[0] == '@':\n",
      "IndexError: string index out of range\n",
      "Interface DataSink failed to run. \n",
      "\n",
      "INFO:workflow:***********************************\n",
      "ERROR:workflow:could not run node: prebandpass.datasink\n",
      "INFO:workflow:crashfile: /homes_unix/hirsch/_ipnotebooks/crash-20170317-121740-hirsch-datasink-0b512184-2feb-44ee-af60-2ea1586d77e9.pklz\n",
      "INFO:workflow:***********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1             2         3             4  \\\n",
      "0  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000  2.848359e-35   \n",
      "1  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305 -5.038878e-05   \n",
      "2  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359 -5.419149e-05   \n",
      "3  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042  1.485895e-05   \n",
      "4  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036  8.939434e-05   \n",
      "\n",
      "              5  \n",
      "0  2.768145e-18  \n",
      "1  3.284350e-05  \n",
      "2  1.160633e-04  \n",
      "3 -5.470219e-06  \n",
      "4 -1.247659e-04  \n",
      "             0             1             2         3             4   \\\n",
      "0  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000  2.848359e-35   \n",
      "1  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305 -5.038878e-05   \n",
      "2  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359 -5.419149e-05   \n",
      "3  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042  1.485895e-05   \n",
      "4  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036  8.939434e-05   \n",
      "\n",
      "             5             6             7             8         9   \\\n",
      "0  2.768145e-18  1.332086e-14 -1.111059e-14  7.105427e-15  0.000000   \n",
      "1  3.284350e-05  1.394313e-03  3.979120e-02 -6.179350e-04 -0.000305   \n",
      "2  1.160633e-04  4.798411e-03  3.080263e-02 -9.149480e-04 -0.000359   \n",
      "3 -5.470219e-06  3.124971e-03  5.745299e-02  2.872896e-03 -0.000042   \n",
      "4 -1.247659e-04  5.558033e-04  5.724530e-02 -1.848545e-02  0.000036   \n",
      "\n",
      "             10            11  \n",
      "0  2.848359e-35  2.768145e-18  \n",
      "1 -5.038878e-05  3.284350e-05  \n",
      "2 -5.419149e-05  1.160633e-04  \n",
      "3  1.485895e-05 -5.470219e-06  \n",
      "4  8.939434e-05 -1.247659e-04  \n",
      "None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0074689e085d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# the run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprebandpass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'write_provenance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     96\u001b[0m                             'Check log for details'))\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "# the run\n",
    "prebandpass.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of precalculations dump in ortho.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/homes_unix/hirsch/_ipnotebooks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mocoFile = '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeMoco.inputs.mocoFile=mocoFile\n",
    "res = computeMoco(mocoFile).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def mocoOrtho(f):\n",
    "    df = pd.read_csv(f, header=None, sep='  ',engine='python')\n",
    "    dfd = plusDerivative(df)\n",
    "    dfs = plusSquare(dfd)\n",
    "    g = dfs.to_csv('ortho.txt', sep=' ', index=False,header=False)\n",
    "    print g\n",
    "    h = os.getcwd() + '/' + 'ortho.txt'\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mocoOrtho('/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal/rp_at0009_epi_s04_d0001.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ImageMeants().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Node: fsconv.editWmMask     \n",
    "editWmMask = Node(MathsCommand(), name=\"editWmMask\")     \n",
    "editWmMask.inputs.args = '-thr 0 -uthr 111 -bin -ero -ero -ero '     \n",
    "editWmMask.inputs.ignore_exception = False     \n",
    "editWmMask.inputs.output_type = 'NIFTI_GZ'     \n",
    "editWmMask.inputs.terminal_output = 'stream'     \n",
    "fsconv.connect(fsWm2Nii, \"out_file\", editWmMask, \"in_file\")\n",
    "\n",
    "from web\n",
    "##############################################################################################\n",
    "##erode a mask or image by zeroing non-zero voxels when zero voxels found in kernel\n",
    "##############################################################################################\n",
    "fslmaths 'mask.nii.gz' -kernel box 5x5x5 -ero 'output_image.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd '/homes_unix/hirsch/_pypipe/datadir/data_results/functionnal'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "square = plusSquare(derivate)\n",
    "print(square.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorSquare(mocodf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(mocodf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorderivative(mocodf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TR = 2000 \n",
    "acqNb = 240\n",
    "\n",
    "dx = {}\n",
    "for i in range(acqNb):\n",
    "    # print mocodf['x'][i]\n",
    "    if i== 0:\n",
    "        dx[i]= (mocodf['x'][i+1]-mocodf['x'][i]) / 2*TR\n",
    "    elif i== acqNb-1:\n",
    "        dx[i]= (mocodf['x'][i]-mocodf['x'][i-1]) / 2*TR \n",
    "    else:\n",
    "        dx[i]= (mocodf['x'][i+1]-mocodf['x'][i-1]) / 2*TR\n",
    "    print 'derivative' + str(i)\n",
    "    print  dx[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdx = pd.Series(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
