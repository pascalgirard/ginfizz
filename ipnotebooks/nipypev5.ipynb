{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plus slice timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.rapidart as ra      # artifact detection\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "import os                                    # system functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm_standalone='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/run_spm12.sh'\n",
    "mcr='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import spm\n",
    "\n",
    "# essai du mercredi soir matlab_cmd = ' '.join([spm_standalone,mcr,'batch','script'])\n",
    "matlab_cmd = ' '.join([spm_standalone,mcr,'batch'])\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype\n",
    "# Optional: Use the following lines to increase verbosity of output\n",
    "nipype.config.set('logging', 'workflow_level',  'INFO')\n",
    "nipype.config.set('logging', 'interface_level', 'INFO')\n",
    "nipype.logging.update_logging(nipype.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - we decode the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flibasedir = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we get the xml file in this directory\n",
    "def getXmlFile(flibasedir):\n",
    "    import os\n",
    "    dirs = os.listdir( flibasedir )\n",
    "    #print dirs\n",
    "\n",
    "    import re\n",
    "    xmlmatch = r'(.*)xml'\n",
    "    for dir in dirs:\n",
    "        xmlfound=re.search(xmlmatch,dir,flags=0)\n",
    "        if xmlfound:\n",
    "            #print xmlfound.group()\n",
    "            return flibasedir + '/' + xmlfound.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/xml_example.xml\n"
     ]
    }
   ],
   "source": [
    "xmlfile = getXmlFile(flibasedir)\n",
    "\n",
    "print xmlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the we decode the xmlfile\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xmlfile)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS_analysis\n"
     ]
    }
   ],
   "source": [
    "print root.tag\n",
    "\n",
    "def getEpiInfos(xmlfile):\n",
    "    result = {}\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # epibold directory\n",
    "        for epibold in root.iter('EPIBOLD'):\n",
    "            for child in epibold:\n",
    "                print child.text\n",
    "                if child.tag == 'file':\n",
    "                    epidir = child.text\n",
    "                    result['epidir'] = epidir\n",
    "                    print epidir\n",
    "                    \n",
    "                # parameters\n",
    "                if child.tag == 'parameters':\n",
    "                    print \"parameters\"\n",
    "                    \n",
    "                    for child2 in child:\n",
    "                                                     \n",
    "                        # TR\n",
    "                        if child2.tag == 'TR':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    tr = child3.text\n",
    "                                    print tr\n",
    "                                    result['TR'] = tr\n",
    "                    \n",
    "                        # dynamics\n",
    "                        if child2.tag == 'dynamics':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    dynamics = child3.text\n",
    "                                    result['dynamics'] = dynamics\n",
    "                                    \n",
    "                        # sliceTimingVector\n",
    "                        if child2.tag == 'sliceTimingVector':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    sliceTimingVector = child3.text\n",
    "                                    result['sliceTimingVector'] = sliceTimingVector\n",
    "                                    \n",
    "                        # nb_slices\n",
    "                        if child2.tag == 'nb_slices':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    nb_slices = child3.text\n",
    "                                    result['nb_slices'] = nb_slices\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        print 'exception'\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n",
      "{'sliceTimingVector': '1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30', 'dynamics': '240', 'nb_slices': '31', 'TR': '2', 'epidir': '/EPIBOLD/'}\n"
     ]
    }
   ],
   "source": [
    "epiResults = getEpiInfos(xmlfile)\n",
    "print epiResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getT1file(xmlfile):\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # T1 directory and file\n",
    "        for t1 in root.iter('T1'):\n",
    "            for child in t1:\n",
    "                #print child.text\n",
    "                if child.tag == 'file':\n",
    "                    t1 = child.text\n",
    "                    t1 = flibasedir + t1\n",
    "                    # print  t1\n",
    "    except:\n",
    "        print 'exception'\n",
    "    return t1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/T1/t0009_t1_s03.nii\n"
     ]
    }
   ],
   "source": [
    "t1 = getT1file(xmlfile)\n",
    "print t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pileline declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - first node data grabbing by select files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T1': <undefined>, 'epi': <undefined>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epidir = getEpiInfos(xmlfile)['epidir']\n",
    "epidir = flibasedir + epidir\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(T1=t1,\n",
    "                 epi= epidir + \"/\" + \"*.nii\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - segment T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment = pe.Node(interface=spm.NewSegment(), name='segment')\n",
    "\n",
    "#seg.inputs.channel_files = 't0009_t1_s03.nii'\n",
    "segment.inputs.channel_info =(0.001,60.0,(True,True))          \n",
    "segment.inputs.sampling_distance= 3.0\n",
    "# todo donner un chemin de TPM.nii comme argument de la future fct\n",
    "tissue1 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 1), 1, (True,False), (False, False))\n",
    "tissue2 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 2), 1, (True,False), (False, False))\n",
    "tissue3 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 3), 2, (True,False), (False, False))\n",
    "tissue4 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 4), 3, (True,False), (False, False))\n",
    "tissue5 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 5), 4, (True,False), (False, False))\n",
    "tissue6 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 6), 2, (False,False), (False, False))\n",
    "segment.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "segment.inputs.affine_regularization = 'mni'\n",
    "#segment.inputs.warping_regularization = [0.0, 0.001, 0.5, 0.05, 0.2]\n",
    "segment.inputs.write_deformation_fields = [False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - slice timing of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "st = pe.Node(interface=spm.SliceTiming(), name='st')\n",
    "#st.inputs.in_files = 'functional.nii'\n",
    "st.inputs.num_slices = int(epiResults['nb_slices'])\n",
    "st.inputs.time_repetition = float(epiResults['TR'])\n",
    "st.inputs.time_acquisition = float(epiResults['TR']) - float(epiResults['TR'])/2.0\n",
    "st.inputs.slice_order = lint\n",
    "st.inputs.ref_slice = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - realign of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realign = pe.Node(interface=spm.Realign(), name='realign')\n",
    "\n",
    "realign.inputs.register_to_mean = True\n",
    "realign.inputs.quality = 0.9\n",
    "realign.inputs.separation = 4\n",
    "realign.inputs.fwhm = 5\n",
    "realign.inputs.interp = 2\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "realign.inputs.write_which = [0, 1]\n",
    "realign.inputs.write_interp = 4\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "realign.inputs.write_mask = True\n",
    "realign.inputs.out_prefix = 'r'\n",
    "realign.inputs.jobtype = 'write'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spm.Coregister()\n",
    "coregister = pe.Node(interface=spm.Coregister(), name='coregister' )\n",
    "\n",
    "coregister.inputs.cost_function = 'nmi'\n",
    "coregister.inputs.separation = [4.0, 2.0]\n",
    "coregister.inputs.jobtype = 'write'\n",
    "coregister.inputs.tolerance = [0.02, 0.02, 0.02, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]\n",
    "coregister.inputs.fwhm = [7.0, 7.0]\n",
    "coregister.inputs.write_interp = 4\n",
    "coregister.inputs.write_wrap = [0, 0, 0]\n",
    "coregister.inputs.write_mask = False \n",
    "coregister.inputs.out_prefix = 'c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm12 = pe.Node(interface=spm.Normalize12(), name='norm12')\n",
    "\n",
    "norm12.inputs.bias_regularization = 0.0001\n",
    "norm12.inputs.bias_fwhm = 60\n",
    "# todo putthis parameter in args of a fct\n",
    "norm12.inputs.tpm = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii'\n",
    "norm12.inputs.affine_regularization_type = 'mni'\n",
    "norm12.inputs.sampling_distance = 3.0\n",
    "norm12.inputs.write_bounding_box = [[-90.0, -126.0, -72.0],[ 90.0, 90.0, 108.0]]\n",
    "norm12.inputs.write_voxel_sizes = [2.0, 2.0, 2.0]\n",
    "norm12.inputs.write_interp = 4\n",
    "norm12.inputs.jobtype = 'write'\n",
    "#norm12.inputs.out_prefix = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connection du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect(filesource,\"T1\" ,segment, 'channel_files')\n",
    "preproc.connect(filesource,\"epi\" ,st, 'in_files')\n",
    "preproc.connect(st,\"timecorrected_files\" ,realign, 'in_files')\n",
    "preproc.connect(segment,\"bias_corrected_images\" ,coregister, 'source')\n",
    "preproc.connect(realign,\"mean_image\" ,coregister, 'target')\n",
    "\n",
    "preproc.connect(realign,\"realigned_files\" ,coregister, 'apply_to_files')\n",
    "\n",
    "preproc.connect(segment,\"bias_corrected_images\" ,norm12, 'image_to_align')\n",
    "preproc.connect(coregister,\"coregistered_files\" ,norm12, 'apply_to_files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the results in the datasink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment results\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n",
    "preproc.connect(segment,  'bias_field_images' , datasink, 'structural.@par1')\n",
    "preproc.connect(segment,  'forward_deformation_field' , datasink, 'structural.@par2')\n",
    "preproc.connect(segment,  'inverse_deformation_field' , datasink, 'structural.@par3')\n",
    "preproc.connect(segment,  'modulated_class_images' , datasink, 'structural.@par4')\n",
    "preproc.connect(segment,  'native_class_images' , datasink, 'structural.@par5')\n",
    "preproc.connect(segment,  'transformation_mat' , datasink, 'structural.@par6')\n",
    "preproc.connect(segment,  'dartel_input_images' , datasink, 'structural.@par7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice timing results\n",
    "preproc.connect(st,  'timecorrected_files', datasink, 'functionnal')\n",
    "\n",
    "# realign mean_image and realignment_parameters\n",
    "preproc.connect(realign,  'mean_image', datasink, 'functionnal.@par')\n",
    "preproc.connect(realign,  'realignment_parameters', datasink, 'functionnal.@par1')\n",
    "preproc.connect(realign,  'realigned_files', datasink, 'functionnal.@par2')\n",
    "preproc.connect(coregister,  'coregistered_files', datasink, 'functionnal.@par3')\n",
    "\n",
    "preproc.connect(norm12,  'normalized_files', datasink, 'functionnal.@par4')\n",
    "preproc.connect(norm12,  'normalized_image', datasink, 'functionnal.@par5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmptJn_2W/preproc/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node st in dir: /tmp/tmpApK6_O/preproc/st\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node realign in dir: /tmp/tmptS9aU2/preproc/realign\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node segment in dir: /tmp/tmp7eL1QR/preproc/segment\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node coregister in dir: /tmp/tmpDC5CQd/preproc/coregister\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node norm12 in dir: /tmp/tmp_UZ2fo/preproc/norm12\n",
      "ERROR:workflow:['Node norm12 failed to run on host pipeau.dgin.bor.']\n",
      "INFO:workflow:Saving crash info to /homes_unix/hirsch/_ipnotebooks/crash-20170308-200234-hirsch-norm12-54b0240f-e5ae-4ce1-807c-e03e94fcba4b.pklz\n",
      "INFO:workflow:Traceback (most recent call last):\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 39, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 394, in run\n",
      "    self._run_interface()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 504, in _run_interface\n",
      "    self._result = self._run_command(execute)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 630, in _run_command\n",
      "    result = self._interface.run()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1034, in run\n",
      "    runtime = self._run_wrapper(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 991, in _run_wrapper\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/spm/base.py\", line 311, in _run_interface\n",
      "    results = self.mlab.run()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1034, in run\n",
      "    runtime = self._run_wrapper(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1660, in _run_wrapper\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/matlab.py\", line 149, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1618, in raise_exception\n",
      "    raise RuntimeError(message)\n",
      "RuntimeError: Command:\n",
      "/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/run_spm12.sh /homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91 batch /tmp/tmp_UZ2fo/preproc/norm12/pyscript_normalize12.m\n",
      "Standard output:\n",
      "------------------------------------------\n",
      "Setting up environment variables\n",
      "---\n",
      "LD_LIBRARY_PATH is .:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91/runtime/glnxa64:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91/bin/glnxa64:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91/sys/os/glnxa64:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91/sys/opengl/lib/glnxa64\n",
      "SPM12 (6906): /homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12\n",
      " ___  ____  __  __                                            \n",
      "/ __)(  _ \\(  \\/  )                                           \n",
      "\\__ \\ )___/ )    (   Statistical Parametric Mapping           \n",
      "(___/(__)  (_/\\/\\_)  SPM12 - http://www.fil.ion.ucl.ac.uk/spm/\n",
      "\n",
      "Executing spm_jobman at 08-Mar-2017 20:02:26:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MATLAB Version: 9.1.0.441655 (R2016b)\n",
      "MATLAB License Number: unknown\n",
      "Operating System: Linux 3.10.0-514.6.1.el7.x86_64 #1 SMP Wed Jan 18 13:06:36 UTC 2017 x86_64\n",
      "Java Version: Java 1.7.0_60-b19 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MATLAB                                                Version 9.1         (R2016b)\n",
      "MATLAB                                                Version 9.1         (R2016b)\n",
      "MATLAB Compiler                                       Version 6.3         (R2016b)\n",
      "SPM version: SPM12 Release: 6906\n",
      "SPM path: /homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm.m\n",
      "Item subj: No field(s) named\n",
      "vol\n",
      "Item write: No field(s) named\n",
      "eoptions\n",
      "Item subj: No field(s) named\n",
      "vol\n",
      "Item write: No field(s) named\n",
      "eoptions\n",
      "Execution failed: /tmp/tmp_UZ2fo/preproc/norm12/pyscript_normalize12.mBye for now...\n",
      "\n",
      "\n",
      "Standard error:\n",
      "No protocol specified\n",
      "MATLAB code threw an exception:\n",
      "No executable modules, but still unresolved dependencies or incomplete module inputs.\n",
      "File:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm_jobman.m\n",
      "Name:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm_jobman.m\n",
      "Line:47\n",
      "File:homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm_jobman.m\n",
      "Name:/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm_jobman.m\n",
      "Line:47\n",
      "File:homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/spm12_mcr/spm12/spm_standalone.m\n",
      "Name:fill_run_job\n",
      "Line:115\n",
      "File:pm_jobman\n",
      "Name:load_jobs\n",
      "Line:115\n",
      "File:pm_jobman\n",
      "Name:spm_standalone\n",
      "Line:461\n",
      "File:\\xf7\n",
      "Name:\\u0149\n",
      "Line:143\n",
      "File:!\n",
      "Name:\n",
      "Return code: 0\n",
      "Interface MatlabCommand failed to run. \n",
      "Interface Normalize12 failed to run. \n",
      "\n",
      "INFO:workflow:***********************************\n",
      "ERROR:workflow:could not run node: preproc.norm12\n",
      "INFO:workflow:crashfile: /homes_unix/hirsch/_ipnotebooks/crash-20170308-200234-hirsch-norm12-54b0240f-e5ae-4ce1-807c-e03e94fcba4b.pklz\n",
      "INFO:workflow:***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-d39d5c1afb77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'write_provenance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     96\u001b[0m                             'Check log for details'))\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use spm_coreg for estimating cross-modality rigid body alignment\n",
      "\n",
      "http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=39\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> import nipype.interfaces.spm as spm\n",
      ">>> coreg = spm.Coregister()\n",
      ">>> coreg.inputs.target = 'functional.nii'\n",
      ">>> coreg.inputs.source = 'structural.nii'\n",
      ">>> coreg.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tsource: (a list of items which are an existing file name)\n",
      "\t\tfile to register to target\n",
      "\ttarget: (an existing file name)\n",
      "\t\treference file to register to\n",
      "\n",
      "\t[Optional]\n",
      "\tapply_to_files: (a list of items which are an existing file name)\n",
      "\t\tfiles to apply transformation to\n",
      "\tcost_function: ('mi' or 'nmi' or 'ecc' or 'ncc')\n",
      "\t\tcost function, one of: 'mi' - Mutual Information,\n",
      "\t\t 'nmi' - Normalised Mutual Information,\n",
      "\t\t 'ecc' - Entropy Correlation Coefficient,\n",
      "\t\t 'ncc' - Normalised Cross Correlation\n",
      "\tfwhm: (a list of from 2 to 2 items which are a float)\n",
      "\t\tgaussian smoothing kernel width (mm)\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tjobtype: ('estwrite' or 'estimate' or 'write', nipype default value:\n",
      "\t\t estwrite)\n",
      "\t\tone of: estimate, write, estwrite\n",
      "\tmatlab_cmd: (a string)\n",
      "\t\tmatlab command to use\n",
      "\tmfile: (a boolean, nipype default value: True)\n",
      "\t\tRun m-code using m-file\n",
      "\tout_prefix: (a string, nipype default value: r)\n",
      "\t\tcoregistered output prefix\n",
      "\tpaths: (a list of items which are a directory name)\n",
      "\t\tPaths to add to matlabpath\n",
      "\tseparation: (a list of items which are a float)\n",
      "\t\tsampling separation in mm\n",
      "\ttolerance: (a list of items which are a float)\n",
      "\t\tacceptable tolerance for each of 12 params\n",
      "\tuse_mcr: (a boolean)\n",
      "\t\tRun m-code using SPM MCR\n",
      "\tuse_v8struct: (a boolean, nipype default value: True)\n",
      "\t\tGenerate SPM8 and higher compatible jobs\n",
      "\twrite_interp: (0 <= an integer <= 7)\n",
      "\t\tdegree of b-spline used for interpolation\n",
      "\twrite_mask: (a boolean)\n",
      "\t\tTrue/False mask output image\n",
      "\twrite_wrap: (a list of from 3 to 3 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tCheck if interpolation should wrap in [x,y,z]\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tcoregistered_files: (a list of items which are an existing file name)\n",
      "\t\tCoregistered other files\n",
      "\tcoregistered_source: (a list of items which are an existing file\n",
      "\t\t name)\n",
      "\t\tCoregistered source files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spm.Coregister.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(epiResults['TR']) - float(epiResults['TR'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_corrected_images = <undefined>\n",
    "bias_field_images = <undefined>\n",
    "dartel_input_images = <undefined>\n",
    "forward_deformation_field = <undefined>\n",
    "inverse_deformation_field = <undefined>\n",
    "modulated_class_images = <undefined>\n",
    "native_class_images = <undefined>\n",
    "normalized_class_images = <undefined>\n",
    "transformation_mat = <undefined>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#advanced way to connect multiple nodes\n",
    "workflowname.connect([(nodename1, nodename2, [('output_node1', 'input_node2')]),\n",
    "                      (nodename1, nodename3, [('output_node1', 'input1_node3')]),\n",
    "                      (nodename2, nodename3, [('output1_node2', 'input1_node3'),\n",
    "                                              ('output2_node2', 'input2_node3')\n",
    "                                              ])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect([(filesource, segment, [('T1', 'channel_files')]),\n",
    "                      (segment, datasink, [('normalized_class_images', 'normalized'),\n",
    "                                              ('bias_corrected_images', 'bias_corrected')\n",
    "                                              ])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.output_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Where should the output data be stored at?\n",
    "sink = nipype.DataSink()\n",
    "sink.inputs.base_directory = experiment_dir + '/output_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd /homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/EPIBOLD\n",
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
