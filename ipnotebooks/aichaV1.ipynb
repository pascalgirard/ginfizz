{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "\n",
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "from nipype.interfaces.fsl.utils import PlotMotionParams   # to plot moco variabl\n",
    "from nipype import SelectFiles, Node\n",
    "\n",
    "from ginnipi.toolbox.computations import extract_atlas_ROIs, create_gexf_graph, compute_correlation_matrix\n",
    "import os\n",
    "import ginnipi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AICHA ROI extraction / mean calculation Workflow Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creation of a subworflow to process ROI Correlations\n",
    "connectivity = pe.Workflow(name='connectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bpFile': <undefined>, 'maskFile': <undefined>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpdir = '/scratch/user/hirsch/datadir4/data_results_py/functionnal/bandpassedFile'\n",
    "maskdir = '/scratch/user/hirsch/datadir4/data_results_py/structural/normalized_files'\n",
    "\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(bpFile=bpdir+ \"/\" + \"*merged_bp.nii.gz\",\n",
    "                 maskFile=maskdir + \"/\" + \"wc1*.nii\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Node: func2.AICHA_ts_extract  \n",
    "from ginnipi.toolbox.computations import extract_atlas_ROIs, create_gexf_graph, compute_correlation_matrix\n",
    "\n",
    "func2_atlas=os.path.join(os.path.dirname(ginnipi.__file__),'share','atlas','AICHA-2mm.nii.gz')                        \n",
    "func2_xml=os.path.join(os.path.dirname(ginnipi.__file__),'share','atlas','AICHA_Short.xml')\n",
    "\n",
    "AICHA_ts_extract = Node(Function(input_names=['bpFile', 'mask_file', 'atlas_file', 'atlas_xml','eig'],                                      \n",
    "                                 output_names=['out_ts_file'],                                      \n",
    "                                 function=extract_atlas_ROIs), name=\"AICHA_ts_extract\")     \n",
    "AICHA_ts_extract.inputs.atlas_file = func2_atlas     \n",
    "AICHA_ts_extract.inputs.atlas_xml = func2_xml     \n",
    "AICHA_ts_extract.inputs.ignore_exception = False   \n",
    "# mean calculation on AICHA ROI \n",
    "AICHA_ts_extract.inputs.eig=False    \n",
    "connectivity.connect(filesource, \"bpFile\", AICHA_ts_extract, \"timeseries_file\")     \n",
    "connectivity.connect(filesource, \"maskFile\", AICHA_ts_extract, \"mask_file\")   # grey matter mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Node: func2.AICHA_cormat\n",
    "from ginnipi.toolbox.computations import extract_atlas_ROIs, create_gexf_graph, compute_correlation_matrix\n",
    "\n",
    "AICHA_cormat = Node(Function(input_names=['in_file'], \n",
    "                                 output_names=['out_file', 'out_file2'],\n",
    "                                 function=compute_correlation_matrix), name=\"AICHA_cormat\")\n",
    "AICHA_cormat.inputs.ignore_exception = False\n",
    "connectivity.connect(AICHA_ts_extract, \"out_ts_file\", AICHA_cormat, \"in_file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output node\n",
    "outputNode = Node(IdentityInterface(fields=['out_file', 'out_file2']), name=\"outputNode\")\n",
    "\n",
    "# for correlation matrix\n",
    "connectivity.connect(AICHA_cormat,  'out_file', outputNode, 'out_file')\n",
    "connectivity.connect(AICHA_cormat,  'out_file2', outputNode, 'out_file2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data sink\n",
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/scratch/user/hirsch/datadir4/data_results_py'\n",
    "\n",
    "# for motion correction  plot files\n",
    "connectivity.connect(outputNode,  'out_file', datasink, 'functionnal.aicha_correlaion_matrix')\n",
    "connectivity.connect(outputNode,  'out_file2', datasink, 'functionnal.@2aicha_correlaion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmpFszn9t/connectivity/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node AICHA_ts_extract in dir: /tmp/tmpU35mut/connectivity/AICHA_ts_extract\n",
      "ERROR:workflow:['Node AICHA_ts_extract failed to run on host pipeau.dgin.bor.']\n",
      "INFO:workflow:Saving crash info to /homes_unix/hirsch/_ipnotebooks/crash-20170426-115505-hirsch-AICHA_ts_extract-59b8cc58-d8b4-49ff-9c67-153f18fde33b.pklz\n",
      "INFO:workflow:Traceback (most recent call last):\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 39, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 394, in run\n",
      "    self._run_interface()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 504, in _run_interface\n",
      "    self._result = self._run_command(execute)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 630, in _run_command\n",
      "    result = self._interface.run()\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1034, in run\n",
      "    runtime = self._run_wrapper(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 991, in _run_wrapper\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/interfaces/utility.py\", line 496, in _run_interface\n",
      "    raise out\n",
      "TypeError: extract_atlas_ROIs() takes at least 4 arguments (4 given)\n",
      "Interface Function failed to run. \n",
      "\n",
      "INFO:workflow:***********************************\n",
      "ERROR:workflow:could not run node: connectivity.AICHA_ts_extract\n",
      "INFO:workflow:crashfile: /homes_unix/hirsch/_ipnotebooks/crash-20170426-115505-hirsch-AICHA_ts_extract-59b8cc58-d8b4-49ff-9c67-153f18fde33b.pklz\n",
      "INFO:workflow:***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ca9c1a3df9d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# the RUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconnectivity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_report'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'execution'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'write_provenance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/srv/shares/softs/anaconda2/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[1;34m(notrun)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***********************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[0;32m     96\u001b[0m                             'Check log for details'))\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "# the RUN\n",
    "\n",
    "connectivity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
