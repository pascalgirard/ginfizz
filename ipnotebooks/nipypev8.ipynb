{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plus slice timing + 16 mars normalisation des images structurelles segmentees en tissus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.rapidart as ra      # artifact detection\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "import os                                    # system functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm_standalone='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/run_spm12.sh'\n",
    "mcr='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import spm\n",
    "\n",
    "# essai du mercredi soir matlab_cmd = ' '.join([spm_standalone,mcr,'batch','script'])\n",
    "matlab_cmd = ' '.join([spm_standalone,mcr,'batch'])\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype\n",
    "# Optional: Use the following lines to increase verbosity of output\n",
    "nipype.config.set('logging', 'workflow_level',  'INFO')\n",
    "nipype.config.set('logging', 'interface_level', 'INFO')\n",
    "nipype.logging.update_logging(nipype.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - we decode the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flibasedir = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we get the xml file in this directory\n",
    "def getXmlFile(flibasedir):\n",
    "    import os\n",
    "    dirs = os.listdir( flibasedir )\n",
    "    #print dirs\n",
    "\n",
    "    import re\n",
    "    xmlmatch = r'(.*)xml'\n",
    "    for dir in dirs:\n",
    "        xmlfound=re.search(xmlmatch,dir,flags=0)\n",
    "        if xmlfound:\n",
    "            #print xmlfound.group()\n",
    "            return flibasedir + '/' + xmlfound.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/xml_example.xml\n"
     ]
    }
   ],
   "source": [
    "xmlfile = getXmlFile(flibasedir)\n",
    "\n",
    "print xmlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the we decode the xmlfile\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xmlfile)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS_analysis\n"
     ]
    }
   ],
   "source": [
    "print root.tag\n",
    "\n",
    "def getEpiInfos(xmlfile):\n",
    "    result = {}\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # epibold directory\n",
    "        for epibold in root.iter('EPIBOLD'):\n",
    "            for child in epibold:\n",
    "                print child.text\n",
    "                if child.tag == 'file':\n",
    "                    epidir = child.text\n",
    "                    result['epidir'] = epidir\n",
    "                    print epidir\n",
    "                    \n",
    "                # parameters\n",
    "                if child.tag == 'parameters':\n",
    "                    print \"parameters\"\n",
    "                    \n",
    "                    for child2 in child:\n",
    "                                                     \n",
    "                        # TR\n",
    "                        if child2.tag == 'TR':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    tr = child3.text\n",
    "                                    print tr\n",
    "                                    result['TR'] = tr\n",
    "                    \n",
    "                        # dynamics\n",
    "                        if child2.tag == 'dynamics':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    dynamics = child3.text\n",
    "                                    result['dynamics'] = dynamics\n",
    "                                    \n",
    "                        # sliceTimingVector\n",
    "                        if child2.tag == 'sliceTimingVector':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    sliceTimingVector = child3.text\n",
    "                                    result['sliceTimingVector'] = sliceTimingVector\n",
    "                                    \n",
    "                        # nb_slices\n",
    "                        if child2.tag == 'nb_slices':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    nb_slices = child3.text\n",
    "                                    result['nb_slices'] = nb_slices\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        print 'exception'\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n",
      "{'sliceTimingVector': '1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30', 'dynamics': '240', 'nb_slices': '31', 'TR': '2', 'epidir': '/EPIBOLD/'}\n"
     ]
    }
   ],
   "source": [
    "epiResults = getEpiInfos(xmlfile)\n",
    "print epiResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getT1file(xmlfile):\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # T1 directory and file\n",
    "        for t1 in root.iter('T1'):\n",
    "            for child in t1:\n",
    "                #print child.text\n",
    "                if child.tag == 'file':\n",
    "                    t1 = child.text\n",
    "                    t1 = flibasedir + t1\n",
    "                    # print  t1\n",
    "    except:\n",
    "        print 'exception'\n",
    "    return t1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/T1/t0009_t1_s03.nii\n"
     ]
    }
   ],
   "source": [
    "t1 = getT1file(xmlfile)\n",
    "print t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Pileline -> declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - first node data grabbing by select files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T1': <undefined>, 'epi': <undefined>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epidir = getEpiInfos(xmlfile)['epidir']\n",
    "epidir = flibasedir + epidir\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(T1=t1,\n",
    "                 epi= epidir + \"/\" + \"*.nii\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - segment T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment = pe.Node(interface=spm.NewSegment(), name='segment')\n",
    "\n",
    "#seg.inputs.channel_files = 't0009_t1_s03.nii'\n",
    "segment.inputs.channel_info =(0.001,60.0,(True,True))          \n",
    "segment.inputs.sampling_distance= 3.0\n",
    "# todo donner un chemin de TPM.nii comme argument de la future fct\n",
    "tissue1 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 1), 1, (True,False), (False, False))\n",
    "tissue2 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 2), 1, (True,False), (False, False))\n",
    "tissue3 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 3), 2, (True,False), (False, False))\n",
    "tissue4 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 4), 3, (True,False), (False, False))\n",
    "tissue5 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 5), 4, (True,False), (False, False))\n",
    "tissue6 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 6), 2, (False,False), (False, False))\n",
    "segment.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "segment.inputs.affine_regularization = 'mni'\n",
    "#segment.inputs.warping_regularization = [0.0, 0.001, 0.5, 0.05, 0.2]\n",
    "segment.inputs.write_deformation_fields = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - slice timing of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "st = pe.Node(interface=spm.SliceTiming(), name='st')\n",
    "#st.inputs.in_files = 'functional.nii'\n",
    "st.inputs.num_slices = int(epiResults['nb_slices'])\n",
    "st.inputs.time_repetition = float(epiResults['TR'])\n",
    "st.inputs.time_acquisition = float(epiResults['TR']) - float(epiResults['TR'])/2.0\n",
    "st.inputs.slice_order = lint\n",
    "st.inputs.ref_slice = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - realign of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realign = pe.Node(interface=spm.Realign(), name='realign')\n",
    "\n",
    "realign.inputs.register_to_mean = False\n",
    "realign.inputs.quality = 0.9\n",
    "realign.inputs.separation = 4\n",
    "realign.inputs.fwhm = 5\n",
    "realign.inputs.interp = 2\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "# essai au defaut 2, 1 realign.inputs.write_which = [0, 1]\n",
    "realign.inputs.write_which = [2, 1]\n",
    "realign.inputs.write_interp = 4\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "realign.inputs.write_mask = True\n",
    "realign.inputs.out_prefix = 'r'\n",
    "realign.inputs.jobtype = 'write'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spm.Coregister()\n",
    "coregister = pe.Node(interface=spm.Coregister(), name='coregister' )\n",
    "\n",
    "coregister.inputs.cost_function = 'nmi'\n",
    "coregister.inputs.separation = [4.0, 2.0]\n",
    "coregister.inputs.jobtype = 'write'\n",
    "coregister.inputs.tolerance = [0.02, 0.02, 0.02, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]\n",
    "coregister.inputs.fwhm = [7.0, 7.0]\n",
    "coregister.inputs.write_interp = 4\n",
    "coregister.inputs.write_wrap = [0, 0, 0]\n",
    "coregister.inputs.write_mask = False \n",
    "coregister.inputs.out_prefix = 'c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# passage à normalize sans 12 non on repasse en 12 et on prend des param de pierre y\n",
    "norm12 = pe.Node(interface=spm.Normalize12(), name='norm12')\n",
    "\n",
    "norm12.inputs.bias_regularization = 0.0001\n",
    "norm12.inputs.bias_fwhm = 60\n",
    "# todo putthis parameter in args of a fct\n",
    "# norm12.inputs.tpm = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii'\n",
    "norm12.inputs.affine_regularization_type = 'mni'\n",
    "norm12.inputs.sampling_distance = 3.0\n",
    "norm12.inputs.write_bounding_box = [[-90.0, -126.0, -72.0],[ 90.0, 90.0, 108.0]]\n",
    "norm12.inputs.write_voxel_sizes = [2.0, 2.0, 2.0]\n",
    "norm12.inputs.write_interp = 4 \n",
    "norm12.inputs.jobtype = 'write'\n",
    "norm12.inputs.use_v8struct = True\n",
    "#norm12.inputs.out_prefix = 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deuxieme normalisation pour normaliser les masks wm et lcf\n",
    "norm12bis = pe.Node(interface=spm.Normalize12(), name='norm12bis')\n",
    "\n",
    "norm12bis.inputs.bias_regularization = 0.0001\n",
    "norm12bis.inputs.bias_fwhm = 60\n",
    "# todo putthis parameter in args of a fct\n",
    "# norm12.inputs.tpm = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii'\n",
    "norm12bis.inputs.affine_regularization_type = 'mni'\n",
    "norm12bis.inputs.sampling_distance = 3.0\n",
    "norm12bis.inputs.write_bounding_box = [[-90.0, -126.0, -72.0],[ 90.0, 90.0, 108.0]]\n",
    "norm12bis.inputs.write_voxel_sizes = [2.0, 2.0, 2.0]\n",
    "norm12bis.inputs.write_interp = 4 \n",
    "norm12bis.inputs.jobtype = 'write'\n",
    "norm12bis.inputs.use_v8struct = True\n",
    "#norm12.inputs.out_prefix = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 -fsl merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import Merge\n",
    "fsl_merge = pe.Node(interface=Merge(), name=\"fsl_merge\")     \n",
    " \n",
    "fsl_merge.inputs.dimension = 't'\n",
    "fsl_merge.inputs.output_type = 'NIFTI_GZ'\n",
    "# todo recuperer le TR deja exploité du xml\n",
    "fsl_merge.inputs.tr = 2.0\n",
    "#fsl_merge.inputs.force_even = False     \n",
    "fsl_merge.inputs.ignore_exception = False     \n",
    "#fsl_merge.inputs.sort = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - low pass high pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import afni\n",
    "\n",
    "bandpass = pe.Node(interface=afni.Bandpass(), name='bandpass')\n",
    "# bandpass.inputs.in_file = 'functional.nii'\n",
    "\n",
    "bandpass.inputs.highpass = 0.005\n",
    "bandpass.inputs.lowpass = 0.2\n",
    "bandpass.inputs.automask = False     \n",
    "bandpass.inputs.environ = {}\n",
    "bandpass.inputs.outputtype = 'NIFTI_GZ'     \n",
    "bandpass.inputs.terminal_output = 'stream'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connection du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect(filesource,\"T1\" ,segment, 'channel_files')\n",
    "\n",
    "preproc.connect(filesource,\"epi\" ,st, 'in_files')\n",
    "\n",
    "preproc.connect(st,\"timecorrected_files\" ,realign, 'in_files')\n",
    "\n",
    "preproc.connect(filesource,\"T1\" ,coregister, 'source')\n",
    "preproc.connect(realign,\"mean_image\" ,coregister, 'target')\n",
    "preproc.connect(realign,\"realigned_files\" ,coregister, 'apply_to_files')\n",
    "\n",
    "preproc.connect(segment,\"forward_deformation_field\" ,norm12, \"deformation_file\")\n",
    "preproc.connect(coregister,\"coregistered_files\" ,norm12, 'apply_to_files')\n",
    "# rajout de normalisation des tissus\n",
    "preproc.connect(segment,\"forward_deformation_field\" , norm12bis, \"deformation_file\")\n",
    "preproc.connect(segment,\"native_class_images\" ,norm12bis, 'apply_to_files')\n",
    "\n",
    "preproc.connect(norm12,  'normalized_files', fsl_merge, 'in_files')\n",
    "\n",
    "preproc.connect(fsl_merge,  'merged_file', bandpass, 'in_file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the results in the datasink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment results\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n",
    "preproc.connect(segment,  'bias_field_images' , datasink, 'structural.@par1')\n",
    "preproc.connect(segment,  'forward_deformation_field' , datasink, 'structural.@par2')\n",
    "preproc.connect(segment,  'inverse_deformation_field' , datasink, 'structural.@par3')\n",
    "preproc.connect(segment,  'modulated_class_images' , datasink, 'structural.mod_class')\n",
    "preproc.connect(segment,  'native_class_images' , datasink, 'structural.native_class')\n",
    "preproc.connect(segment,  'transformation_mat' , datasink, 'structural.@par6')\n",
    "preproc.connect(segment,  'dartel_input_images' , datasink, 'structural.@par7')\n",
    "\n",
    "# rajout de normalisation des tissues\n",
    "preproc.connect(norm12bis,  'normalized_files', datasink, 'structural.norm_files')\n",
    "preproc.connect(norm12bis,  'normalized_image', datasink, 'structural.norm_image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice timing results\n",
    "preproc.connect(st,  'timecorrected_files', datasink, 'functionnal')\n",
    "\n",
    "# realign mean_image and realignment_parameters\n",
    "preproc.connect(realign,  'mean_image', datasink, 'functionnal.@par')\n",
    "preproc.connect(realign,  'realignment_parameters', datasink, 'functionnal.@par1')\n",
    "preproc.connect(realign,  'realigned_files', datasink, 'functionnal.@par2')\n",
    "\n",
    "preproc.connect(coregister,  'coregistered_files', datasink, 'functionnal.@par3')\n",
    "\n",
    "preproc.connect(norm12,  'normalized_files', datasink, 'functionnal.norm_files')\n",
    "preproc.connect(norm12,  'normalized_image', datasink, 'functionnal.norm_image')\n",
    "\n",
    "\n",
    "\n",
    "preproc.connect(fsl_merge,  'merged_file', datasink, 'functionnal.@par6')\n",
    "\n",
    "preproc.connect(bandpass,  'out_file', datasink, 'functionnal.@par7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmpCK0_iI/preproc/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node st in dir: /tmp/tmpH0Ke6k/preproc/st\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node realign in dir: /tmp/tmpjtg0GR/preproc/realign\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node coregister in dir: /tmp/tmpeE2D1c/preproc/coregister\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node segment in dir: /tmp/tmpKkD4L7/preproc/segment\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node norm12bis in dir: /tmp/tmpVghRVy/preproc/norm12bis\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node norm12 in dir: /tmp/tmpXgf8wn/preproc/norm12\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node fsl_merge in dir: /tmp/tmpada8pW/preproc/fsl_merge\n",
      "INFO:workflow:Running: fslmerge -tr wcrat0009_epi_s04_d0001_merged.nii.gz /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0001.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0002.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0003.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0004.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0005.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0006.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0007.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0008.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0009.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0010.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0011.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0012.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0013.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0014.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0015.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0016.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0017.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0018.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0019.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0020.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0021.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0022.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0023.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0024.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0025.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0026.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0027.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0028.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0029.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0030.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0031.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0032.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0033.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0034.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0035.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0036.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0037.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0038.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0039.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0040.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0041.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0042.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0043.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0044.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0045.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0046.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0047.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0048.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0049.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0050.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0051.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0052.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0053.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0054.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0055.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0056.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0057.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0058.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0059.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0060.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0061.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0062.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0063.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0064.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0065.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0066.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0067.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0068.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0069.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0070.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0071.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0072.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0073.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0074.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0075.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0076.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0077.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0078.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0079.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0080.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0081.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0082.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0083.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0084.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0085.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0086.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0087.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0088.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0089.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0090.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0091.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0092.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0093.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0094.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0095.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0096.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0097.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0098.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0099.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0100.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0101.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0102.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0103.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0104.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0105.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0106.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0107.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0108.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0109.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0110.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0111.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0112.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0113.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0114.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0115.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0116.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0117.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0118.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0119.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0120.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0121.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0122.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0123.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0124.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0125.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0126.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0127.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0128.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0129.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0130.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0131.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0132.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0133.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0134.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0135.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0136.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0137.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0138.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0139.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0140.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0141.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0142.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0143.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0144.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0145.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0146.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0147.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0148.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0149.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0150.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0151.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0152.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0153.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0154.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0155.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0156.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0157.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0158.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0159.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0160.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0161.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0162.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0163.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0164.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0165.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0166.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0167.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0168.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0169.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0170.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0171.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0172.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0173.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0174.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0175.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0176.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0177.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0178.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0179.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0180.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0181.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0182.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0183.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0184.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0185.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0186.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0187.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0188.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0189.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0190.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0191.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0192.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0193.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0194.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0195.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0196.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0197.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0198.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0199.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0200.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0201.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0202.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0203.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0204.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0205.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0206.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0207.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0208.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0209.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0210.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0211.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0212.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0213.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0214.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0215.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0216.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0217.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0218.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0219.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0220.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0221.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0222.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0223.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0224.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0225.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0226.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0227.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0228.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0229.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0230.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0231.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0232.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0233.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0234.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0235.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0236.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0237.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0238.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0239.nii /tmp/tmpXgf8wn/preproc/norm12/wcrat0009_epi_s04_d0240.nii 2.00\n",
      "INFO:workflow:Executing node bandpass in dir: /tmp/tmplaDTbm/preproc/bandpass\n",
      "INFO:workflow:Running: 3dBandpass -prefix wcrat0009_epi_s04_d0001_merged_bp.nii.gz 0.005000 0.200000 /tmp/tmplaDTbm/preproc/bandpass/wcrat0009_epi_s04_d0001_merged.nii.gz\n",
      "INFO:interface:stderr 2017-03-16T11:11:11.956656:++ 3dBandpass: AFNI version=AFNI_16.0.00 (Jan  1 2016) [64-bit]\n",
      "INFO:interface:stderr 2017-03-16T11:11:11.956656:++ Authored by: RW Cox\n",
      "INFO:interface:stderr 2017-03-16T11:11:11.956656:++ Data length = 240  FFT length = 240\n",
      "INFO:interface:stderr 2017-03-16T11:11:11.956656: + bandpass: ntime=240 nFFT=240 dt=2 dFreq=0.00208333 Nyquist=0.25 passband indexes=2..96\n",
      "INFO:interface:stderr 2017-03-16T11:11:11.956656:++ Loading input dataset time series\n",
      "INFO:interface:stderr 2017-03-16T11:11:19.396543:++ No mask ==> processing all 902629 voxels\n",
      "INFO:interface:stderr 2017-03-16T11:11:19.396543:++ Checking dataset for initial transients [use '-notrans' to skip this test]\n",
      "INFO:interface:stderr 2017-03-16T11:11:23.072450: + No widespread initial positive transient detected :-)\n",
      "INFO:interface:stderr 2017-03-16T11:11:30.453752:++ 240 dimensional data reduced to 187 by:\n",
      "INFO:interface:stderr 2017-03-16T11:11:30.453752:    50 (bandpass), 0 (-ort), 0 (-dsort), 3 (detrend)\n",
      "INFO:interface:stderr 2017-03-16T11:11:30.453752:++ Bandpassing data time series\n",
      "INFO:interface:stderr 2017-03-16T11:11:35.921987:++ Creating output dataset in memory, then writing it\n",
      "INFO:interface:stderr 2017-03-16T11:12:15.388456:++ Output dataset ./wcrat0009_epi_s04_d0001_merged_bp.nii.gz\n",
      "INFO:workflow:Executing node datasink in dir: /tmp/tmpGcCfDG/preproc/datasink\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f913b6d6150>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **fslmerge**\n",
      "\n",
      "Use fslmerge to concatenate images\n",
      "\n",
      "Images can be concatenated across time, x, y, or z dimensions. Across the\n",
      "time (t) dimension the TR is set by default to 1 sec.\n",
      "\n",
      "Note: to set the TR to a different value, specify 't' for dimension and\n",
      "specify the TR value in seconds for the tr input. The dimension will be\n",
      "automatically updated to 'tr'.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.fsl import Merge\n",
      ">>> merger = Merge()\n",
      ">>> merger.inputs.in_files = ['functional2.nii', 'functional3.nii']\n",
      ">>> merger.inputs.dimension = 't'\n",
      ">>> merger.inputs.output_type = 'NIFTI_GZ'\n",
      ">>> merger.cmdline\n",
      "'fslmerge -t functional2_merged.nii.gz functional2.nii functional3.nii'\n",
      ">>> merger.inputs.tr = 2.25\n",
      ">>> merger.cmdline\n",
      "'fslmerge -tr functional2_merged.nii.gz functional2.nii functional3.nii 2.25'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tdimension: ('t' or 'x' or 'y' or 'z' or 'a')\n",
      "\t\tdimension along which to merge, optionally set tr input when\n",
      "\t\tdimension is t\n",
      "\t\tflag: -%s, position: 0\n",
      "\tin_files: (a list of items which are an existing file name)\n",
      "\t\tflag: %s, position: 2\n",
      "\n",
      "\t[Optional]\n",
      "\targs: (a string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tenviron: (a dictionary with keys which are a value of type 'str' and\n",
      "\t\t with values which are a value of type 'str', nipype default value:\n",
      "\t\t {})\n",
      "\t\tEnvironment variables\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tmerged_file: (a file name)\n",
      "\t\tflag: %s, position: 1\n",
      "\toutput_type: ('NIFTI_PAIR' or 'NIFTI_PAIR_GZ' or 'NIFTI_GZ' or\n",
      "\t\t 'NIFTI')\n",
      "\t\tFSL output type\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\ttr: (a float)\n",
      "\t\tuse to specify TR in seconds (default is 1.00 sec), overrides\n",
      "\t\tdimension and sets it to tr\n",
      "\t\tflag: %.2f, position: -1\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tmerged_file: (an existing file name)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.fsl import Merge\n",
    "\n",
    "Merge().help()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Node: fsconv.editWmMask     \n",
    "editWmMask = Node(MathsCommand(), name=\"editWmMask\")     \n",
    "editWmMask.inputs.args = '-thr 0 -uthr 111 -bin -ero -ero -ero '     \n",
    "editWmMask.inputs.ignore_exception = False     \n",
    "editWmMask.inputs.output_type = 'NIFTI_GZ'     \n",
    "editWmMask.inputs.terminal_output = 'stream'     \n",
    "fsconv.connect(fsWm2Nii, \"out_file\", editWmMask, \"in_file\")\n",
    "\n",
    "from web\n",
    "##############################################################################################\n",
    "##erode a mask or image by zeroing non-zero voxels when zero voxels found in kernel\n",
    "##############################################################################################\n",
    "fslmaths 'mask.nii.gz' -kernel box 5x5x5 -ero 'output_image.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **fslmaths**\n",
      "\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_file: (an existing file name)\n",
      "\t\timage to operate on\n",
      "\t\tflag: %s, position: 2\n",
      "\n",
      "\t[Optional]\n",
      "\targs: (a string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tenviron: (a dictionary with keys which are a value of type 'str' and\n",
      "\t\t with values which are a value of type 'str', nipype default value:\n",
      "\t\t {})\n",
      "\t\tEnvironment variables\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tinternal_datatype: ('float' or 'char' or 'int' or 'short' or 'double'\n",
      "\t\t or 'input')\n",
      "\t\tdatatype to use for calculations (default is float)\n",
      "\t\tflag: -dt %s, position: 1\n",
      "\tnan2zeros: (a boolean)\n",
      "\t\tchange NaNs to zeros before doing anything\n",
      "\t\tflag: -nan, position: 3\n",
      "\tout_file: (a file name)\n",
      "\t\timage to write\n",
      "\t\tflag: %s, position: -2\n",
      "\toutput_datatype: ('float' or 'char' or 'int' or 'short' or 'double'\n",
      "\t\t or 'input')\n",
      "\t\tdatatype to use for output (default uses input type)\n",
      "\t\tflag: -odt %s, position: -1\n",
      "\toutput_type: ('NIFTI_PAIR' or 'NIFTI_PAIR_GZ' or 'NIFTI_GZ' or\n",
      "\t\t 'NIFTI')\n",
      "\t\tFSL output type\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\timage written after calculations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nipype.interfaces.fsl.maths import MathsCommand\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MathsCommand().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uses SPM12's new Normalise routine for warping an image to a template.\n",
      "Spatial normalisation is now done via the segmentation routine (which was\n",
      "known as ``New Segment`` in SPM8). Note that the normalisation in SPM12\n",
      "is done towards a file containing multiple tissue probability maps, which\n",
      "was not the cass in SPM8.\n",
      "\n",
      "http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=49\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import nipype.interfaces.spm as spm\n",
      ">>> norm12 = spm.Normalize12()\n",
      ">>> norm12.inputs.image_to_align = 'structural.nii'\n",
      ">>> norm12.inputs.apply_to_files = 'functional.nii'\n",
      ">>> norm12.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tdeformation_file: (a file name)\n",
      "\t\tfile y_*.nii containing 3 deformation fields for the deformation in\n",
      "\t\tx, y and z dimension\n",
      "\t\tmutually_exclusive: image_to_align, tpm\n",
      "\timage_to_align: (an existing file name)\n",
      "\t\tfile to estimate normalization parameters with\n",
      "\t\tmutually_exclusive: deformation_file\n",
      "\n",
      "\t[Optional]\n",
      "\taffine_regularization_type: ('mni' or 'size' or 'none')\n",
      "\t\tmni, size, none\n",
      "\tapply_to_files: (a list of items which are an existing file name or a\n",
      "\t\t list of items which are an existing file name)\n",
      "\t\tfiles to apply transformation to\n",
      "\tbias_fwhm: (30 or 40 or 50 or 60 or 70 or 80 or 90 or 100 or 110 or\n",
      "\t\t 120 or 130 or 140 or 150 or 'Inf')\n",
      "\t\tFWHM of Gaussian smoothness of bias\n",
      "\tbias_regularization: (0 or 1e-05 or 0.0001 or 0.001 or 0.01 or 0.1 or\n",
      "\t\t 1 or 10)\n",
      "\t\tno(0) - extremely heavy (10)\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tjobtype: ('estwrite' or 'est' or 'write', nipype default value:\n",
      "\t\t estwrite)\n",
      "\t\tEstimate, Write or do Both\n",
      "\tmatlab_cmd: (a string)\n",
      "\t\tmatlab command to use\n",
      "\tmfile: (a boolean, nipype default value: True)\n",
      "\t\tRun m-code using m-file\n",
      "\tpaths: (a list of items which are a directory name)\n",
      "\t\tPaths to add to matlabpath\n",
      "\tsampling_distance: (a float)\n",
      "\t\tSampling distance on data for parameter estimation\n",
      "\tsmoothness: (a float)\n",
      "\t\tvalue (in mm) to smooth the data before normalization\n",
      "\ttpm: (an existing file name)\n",
      "\t\ttemplate in form of tissue probablitiy maps to normalize to\n",
      "\t\tmutually_exclusive: deformation_file\n",
      "\tuse_mcr: (a boolean)\n",
      "\t\tRun m-code using SPM MCR\n",
      "\tuse_v8struct: (a boolean, nipype default value: True)\n",
      "\t\tGenerate SPM8 and higher compatible jobs\n",
      "\twarping_regularization: (a list of from 5 to 5 items which are a\n",
      "\t\t float)\n",
      "\t\tcontrols balance between parameters and data\n",
      "\twrite_bounding_box: (a list of from 2 to 2 items which are a list of\n",
      "\t\t from 3 to 3 items which are a float)\n",
      "\t\t3x2-element list of lists representing the bounding box (in mm) to\n",
      "\t\tbe written\n",
      "\twrite_interp: (0 <= an integer <= 7)\n",
      "\t\tdegree of b-spline used for interpolation\n",
      "\twrite_voxel_sizes: (a list of from 3 to 3 items which are a float)\n",
      "\t\t3-element list representing the voxel sizes (in mm) of the written\n",
      "\t\tnormalised images\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tdeformation_field: (a list of items which are an existing file name)\n",
      "\t\tNIfTI file containing 3 deformation fields for the deformation in x,\n",
      "\t\ty and z dimension\n",
      "\tnormalized_files: (a list of items which are an existing file name)\n",
      "\t\tNormalized other files\n",
      "\tnormalized_image: (a list of items which are an existing file name)\n",
      "\t\tNormalized file that needed to be aligned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spm.Normalize12().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use spm_realign for estimating within modality rigid body alignment\n",
      "\n",
      "http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=25\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> import nipype.interfaces.spm as spm\n",
      ">>> realign = spm.Realign()\n",
      ">>> realign.inputs.in_files = 'functional.nii'\n",
      ">>> realign.inputs.register_to_mean = True\n",
      ">>> realign.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tin_files: (a list of items which are a list of items which are an\n",
      "\t\t existing file name or an existing file name)\n",
      "\t\tlist of filenames to realign\n",
      "\n",
      "\t[Optional]\n",
      "\tfwhm: (a floating point number >= 0.0)\n",
      "\t\tgaussian smoothing kernel width\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tinterp: (0 <= an integer <= 7)\n",
      "\t\tdegree of b-spline used for interpolation\n",
      "\tjobtype: ('estwrite' or 'estimate' or 'write', nipype default value:\n",
      "\t\t estwrite)\n",
      "\t\tone of: estimate, write, estwrite\n",
      "\tmatlab_cmd: (a string)\n",
      "\t\tmatlab command to use\n",
      "\tmfile: (a boolean, nipype default value: True)\n",
      "\t\tRun m-code using m-file\n",
      "\tout_prefix: (a string, nipype default value: r)\n",
      "\t\trealigned output prefix\n",
      "\tpaths: (a list of items which are a directory name)\n",
      "\t\tPaths to add to matlabpath\n",
      "\tquality: (0.0 <= a floating point number <= 1.0)\n",
      "\t\t0.1 = fast, 1.0 = precise\n",
      "\tregister_to_mean: (a boolean)\n",
      "\t\tIndicate whether realignment is done to the mean image\n",
      "\tseparation: (a floating point number >= 0.0)\n",
      "\t\tsampling separation in mm\n",
      "\tuse_mcr: (a boolean)\n",
      "\t\tRun m-code using SPM MCR\n",
      "\tuse_v8struct: (a boolean, nipype default value: True)\n",
      "\t\tGenerate SPM8 and higher compatible jobs\n",
      "\tweight_img: (an existing file name)\n",
      "\t\tfilename of weighting image\n",
      "\twrap: (a list of from 3 to 3 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tCheck if interpolation should wrap in [x,y,z]\n",
      "\twrite_interp: (0 <= an integer <= 7)\n",
      "\t\tdegree of b-spline used for interpolation\n",
      "\twrite_mask: (a boolean)\n",
      "\t\tTrue/False mask output image\n",
      "\twrite_which: (a list of items which are a value of type 'int', nipype\n",
      "\t\t default value: [2, 1])\n",
      "\t\tdetermines which images to reslice\n",
      "\twrite_wrap: (a list of from 3 to 3 items which are an integer (int or\n",
      "\t\t long))\n",
      "\t\tCheck if interpolation should wrap in [x,y,z]\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tmean_image: (an existing file name)\n",
      "\t\tMean image file from the realignment\n",
      "\tmodified_in_files: (a list of items which are a list of items which\n",
      "\t\t are an existing file name or an existing file name)\n",
      "\t\tCopies of all files passed to in_files. Headers will have been\n",
      "\t\tmodified to align all images with the first, or optionally to first\n",
      "\t\tdo that, extract a mean image, and re-align to that mean image.\n",
      "\trealigned_files: (a list of items which are a list of items which are\n",
      "\t\t an existing file name or an existing file name)\n",
      "\t\tIf jobtype is write or estwrite, these will be the resliced files.\n",
      "\t\tOtherwise, they will be copies of in_files that have had their\n",
      "\t\theaders rewritten.\n",
      "\trealignment_parameters: (a list of items which are an existing file\n",
      "\t\t name)\n",
      "\t\tEstimated translation and rotation parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spm.Realign().help()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ARIMA",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-d8e7b1e21325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named ARIMA"
     ]
    }
   ],
   "source": [
    "import statsmodels.tsa.arima_model.ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps command **3dBandpass**\n",
      "\n",
      "Program to lowpass and/or highpass each voxel time series in a\n",
      "dataset, offering more/different options than Fourier\n",
      "\n",
      "For complete details, see the `3dBandpass Documentation.\n",
      "<http://afni.nimh.nih.gov/pub/dist/doc/program_help/3dbandpass.html>`_\n",
      "\n",
      "Examples\n",
      "========\n",
      "\n",
      ">>> from nipype.interfaces import afni as afni\n",
      ">>> from nipype.testing import  example_data\n",
      ">>> bandpass = afni.Bandpass()\n",
      ">>> bandpass.inputs.in_file = example_data('functional.nii')\n",
      ">>> bandpass.inputs.highpass = 0.005\n",
      ">>> bandpass.inputs.lowpass = 0.1\n",
      ">>> res = bandpass.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\thighpass: (a float)\n",
      "\t\thighpass\n",
      "\t\tflag: %f, position: -3\n",
      "\tin_file: (an existing file name)\n",
      "\t\tinput file to 3dBandpass\n",
      "\t\tflag: %s, position: -1\n",
      "\tlowpass: (a float)\n",
      "\t\tlowpass\n",
      "\t\tflag: %f, position: -2\n",
      "\n",
      "\t[Optional]\n",
      "\targs: (a string)\n",
      "\t\tAdditional parameters to the command\n",
      "\t\tflag: %s\n",
      "\tautomask: (a boolean)\n",
      "\t\tCreate a mask from the input dataset\n",
      "\t\tflag: -automask\n",
      "\tblur: (a float)\n",
      "\t\tBlur (inside the mask only) with a filter\n",
      "\t\t width (FWHM) of 'fff' millimeters.\n",
      "\t\tflag: -blur %f\n",
      "\tdespike: (a boolean)\n",
      "\t\tDespike each time series before other processing.\n",
      "\t\t ++ Hopefully, you don't actually need to do this,\n",
      "\t\t which is why it is optional.\n",
      "\t\tflag: -despike\n",
      "\tenviron: (a dictionary with keys which are a value of type 'str' and\n",
      "\t\t with values which are a value of type 'str', nipype default value:\n",
      "\t\t {})\n",
      "\t\tEnvironment variables\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tlocalPV: (a float)\n",
      "\t\tReplace each vector by the local Principal Vector\n",
      "\t\t (AKA first singular vector) from a neighborhood\n",
      "\t\t of radius 'rrr' millimiters.\n",
      "\t\t ++ Note that the PV time series is L2 normalized.\n",
      "\t\t ++ This option is mostly for Bob Cox to have fun with.\n",
      "\t\tflag: -localPV %f\n",
      "\tmask: (an existing file name)\n",
      "\t\tmask file\n",
      "\t\tflag: -mask %s, position: 2\n",
      "\tnfft: (an integer (int or long))\n",
      "\t\tset the FFT length [must be a legal value]\n",
      "\t\tflag: -nfft %d\n",
      "\tno_detrend: (a boolean)\n",
      "\t\tSkip the quadratic detrending of the input that\n",
      "\t\t occurs before the FFT-based bandpassing.\n",
      "\t\t ++ You would only want to do this if the dataset\n",
      "\t\t had been detrended already in some other program.\n",
      "\t\tflag: -nodetrend\n",
      "\tnormalize: (a boolean)\n",
      "\t\tMake all output time series have L2 norm = 1\n",
      "\t\t ++ i.e., sum of squares = 1\n",
      "\t\tflag: -norm\n",
      "\tnotrans: (a boolean)\n",
      "\t\tDon't check for initial positive transients in the data:\n",
      "\t\t ++ The test is a little slow, so skipping it is OK,\n",
      "\t\t if you KNOW the data time series are transient-free.\n",
      "\t\tflag: -notrans\n",
      "\torthogonalize_dset: (an existing file name)\n",
      "\t\tOrthogonalize each voxel to the corresponding\n",
      "\t\t voxel time series in dataset 'fset', which must\n",
      "\t\t have the same spatial and temporal grid structure\n",
      "\t\t as the main input dataset.\n",
      "\t\t ++ At present, only one '-dsort' option is allowed.\n",
      "\t\tflag: -dsort %s\n",
      "\torthogonalize_file: (a list of items which are an existing file name)\n",
      "\t\tAlso orthogonalize input to columns in f.1D\n",
      "\t\t ++ Multiple '-ort' options are allowed.\n",
      "\t\tflag: -ort %s\n",
      "\tout_file: (a file name)\n",
      "\t\toutput file from 3dBandpass\n",
      "\t\tflag: -prefix %s, position: 1\n",
      "\toutputtype: ('NIFTI_GZ' or 'AFNI' or 'NIFTI')\n",
      "\t\tAFNI output filetype\n",
      "\tterminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
      "\t\tControl terminal output: `stream` - displays to terminal immediately\n",
      "\t\t(default), `allatonce` - waits till command is finished to display\n",
      "\t\toutput, `file` - writes output to file, `none` - output is ignored\n",
      "\ttr: (a float)\n",
      "\t\tset time step (TR) in sec [default=from dataset header]\n",
      "\t\tflag: -dt %f\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tout_file: (an existing file name)\n",
      "\t\toutput file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nipype.interfaces import afni\n",
    "afni.Bandpass().help()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels import  tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm\n",
    "\n",
    ".Normalize12().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Coregister.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(epiResults['TR']) - float(epiResults['TR'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_corrected_images = <undefined>\n",
    "bias_field_images = <undefined>\n",
    "dartel_input_images = <undefined>\n",
    "forward_deformation_field = <undefined>\n",
    "inverse_deformation_field = <undefined>\n",
    "modulated_class_images = <undefined>\n",
    "native_class_images = <undefined>\n",
    "normalized_class_images = <undefined>\n",
    "transformation_mat = <undefined>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use spm_preproc8 (New Segment) to separate structural images into different\n",
      "tissue classes. Supports multiple modalities.\n",
      "\n",
      "NOTE: This interface currently supports single channel input only\n",
      "\n",
      "http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=43\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import nipype.interfaces.spm as spm\n",
      ">>> seg = spm.NewSegment()\n",
      ">>> seg.inputs.channel_files = 'structural.nii'\n",
      ">>> seg.inputs.channel_info = (0.0001, 60, (True, True))\n",
      ">>> seg.run() # doctest: +SKIP\n",
      "\n",
      "For VBM pre-processing [http://www.fil.ion.ucl.ac.uk/~john/misc/VBMclass10.pdf],\n",
      "TPM.nii should be replaced by /path/to/spm8/toolbox/Seg/TPM.nii\n",
      "\n",
      ">>> seg = NewSegment()\n",
      ">>> seg.inputs.channel_files = 'structural.nii'\n",
      ">>> tissue1 = (('TPM.nii', 1), 2, (True,True), (False, False))\n",
      ">>> tissue2 = (('TPM.nii', 2), 2, (True,True), (False, False))\n",
      ">>> tissue3 = (('TPM.nii', 3), 2, (True,False), (False, False))\n",
      ">>> tissue4 = (('TPM.nii', 4), 2, (False,False), (False, False))\n",
      ">>> tissue5 = (('TPM.nii', 5), 2, (False,False), (False, False))\n",
      ">>> seg.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5]\n",
      ">>> seg.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tchannel_files: (a list of items which are an existing file name)\n",
      "\t\tA list of files to be segmented\n",
      "\n",
      "\t[Optional]\n",
      "\taffine_regularization: ('mni' or 'eastern' or 'subj' or 'none')\n",
      "\t\tmni, eastern, subj, none\n",
      "\tchannel_info: (a tuple of the form: (a float, a float, a tuple of the\n",
      "\t\t form: (a boolean, a boolean)))\n",
      "\t\tA tuple with the following fields:\n",
      "\t\t - bias reguralisation (0-10)\n",
      "\t\t - FWHM of Gaussian smoothness of bias\n",
      "\t\t - which maps to save (Corrected, Field) - a tuple of two boolean\n",
      "\t\tvalues\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tmatlab_cmd: (a string)\n",
      "\t\tmatlab command to use\n",
      "\tmfile: (a boolean, nipype default value: True)\n",
      "\t\tRun m-code using m-file\n",
      "\tpaths: (a list of items which are a directory name)\n",
      "\t\tPaths to add to matlabpath\n",
      "\tsampling_distance: (a float)\n",
      "\t\tSampling distance on data for parameter estimation\n",
      "\ttissues: (a list of items which are a tuple of the form: (a tuple of\n",
      "\t\t the form: (an existing file name, an integer (int or long)), an\n",
      "\t\t integer (int or long), a tuple of the form: (a boolean, a boolean),\n",
      "\t\t a tuple of the form: (a boolean, a boolean)))\n",
      "\t\tA list of tuples (one per tissue) with the following fields:\n",
      "\t\t - tissue probability map (4D), 1-based index to frame\n",
      "\t\t - number of gaussians\n",
      "\t\t - which maps to save [Native, DARTEL] - a tuple of two boolean\n",
      "\t\tvalues\n",
      "\t\t - which maps to save [Unmodulated, Modulated] - a tuple of two\n",
      "\t\tboolean values\n",
      "\tuse_mcr: (a boolean)\n",
      "\t\tRun m-code using SPM MCR\n",
      "\tuse_v8struct: (a boolean, nipype default value: True)\n",
      "\t\tGenerate SPM8 and higher compatible jobs\n",
      "\twarping_regularization: (a float)\n",
      "\t\tAproximate distance between sampling points.\n",
      "\twrite_deformation_fields: (a list of from 2 to 2 items which are a\n",
      "\t\t boolean)\n",
      "\t\tWhich deformation fields to write:[Inverse, Forward]\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tbias_corrected_images: (a list of items which are an existing file\n",
      "\t\t name)\n",
      "\t\tbias corrected images\n",
      "\tbias_field_images: (a list of items which are an existing file name)\n",
      "\t\tbias field images\n",
      "\tdartel_input_images: (a list of items which are a list of items which\n",
      "\t\t are an existing file name)\n",
      "\t\tdartel imported class images\n",
      "\tforward_deformation_field: (a list of items which are an existing\n",
      "\t\t file name)\n",
      "\tinverse_deformation_field: (a list of items which are an existing\n",
      "\t\t file name)\n",
      "\tmodulated_class_images: (a list of items which are a list of items\n",
      "\t\t which are an existing file name)\n",
      "\t\tmodulated+normalized class images\n",
      "\tnative_class_images: (a list of items which are a list of items which\n",
      "\t\t are an existing file name)\n",
      "\t\tnative space probability maps\n",
      "\tnormalized_class_images: (a list of items which are a list of items\n",
      "\t\t which are an existing file name)\n",
      "\t\tnormalized class images\n",
      "\ttransformation_mat: (a list of items which are an existing file name)\n",
      "\t\tNormalization transformation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spm.NewSegment.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.output_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd /homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/EPIBOLD\n",
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
