{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plus slice timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.spm as spm          # spm\n",
    "import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.rapidart as ra      # artifact detection\n",
    "import nipype.algorithms.modelgen as model   # model specification\n",
    "import os                                    # system functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm_standalone='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/spm12/run_spm12.sh'\n",
    "mcr='/homes_unix/hirsch/historique_fli_iam/essai_spm_stand_alone/mcr2016/v91'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces import spm\n",
    "\n",
    "# essai du mercredi soir matlab_cmd = ' '.join([spm_standalone,mcr,'batch','script'])\n",
    "matlab_cmd = ' '.join([spm_standalone,mcr,'batch'])\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nipype verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype\n",
    "# Optional: Use the following lines to increase verbosity of output\n",
    "nipype.config.set('logging', 'workflow_level',  'INFO')\n",
    "nipype.config.set('logging', 'interface_level', 'INFO')\n",
    "nipype.logging.update_logging(nipype.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - we decode the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flibasedir = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we get the xml file in this directory\n",
    "def getXmlFile(flibasedir):\n",
    "    import os\n",
    "    dirs = os.listdir( flibasedir )\n",
    "    #print dirs\n",
    "\n",
    "    import re\n",
    "    xmlmatch = r'(.*)xml'\n",
    "    for dir in dirs:\n",
    "        xmlfound=re.search(xmlmatch,dir,flags=0)\n",
    "        if xmlfound:\n",
    "            #print xmlfound.group()\n",
    "            return flibasedir + '/' + xmlfound.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/xml_example.xml\n"
     ]
    }
   ],
   "source": [
    "xmlfile = getXmlFile(flibasedir)\n",
    "\n",
    "print xmlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the we decode the xmlfile\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xmlfile)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS_analysis\n"
     ]
    }
   ],
   "source": [
    "print root.tag\n",
    "\n",
    "def getEpiInfos(xmlfile):\n",
    "    result = {}\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # epibold directory\n",
    "        for epibold in root.iter('EPIBOLD'):\n",
    "            for child in epibold:\n",
    "                print child.text\n",
    "                if child.tag == 'file':\n",
    "                    epidir = child.text\n",
    "                    result['epidir'] = epidir\n",
    "                    print epidir\n",
    "                    \n",
    "                # parameters\n",
    "                if child.tag == 'parameters':\n",
    "                    print \"parameters\"\n",
    "                    \n",
    "                    for child2 in child:\n",
    "                                                     \n",
    "                        # TR\n",
    "                        if child2.tag == 'TR':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    tr = child3.text\n",
    "                                    print tr\n",
    "                                    result['TR'] = tr\n",
    "                    \n",
    "                        # dynamics\n",
    "                        if child2.tag == 'dynamics':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    dynamics = child3.text\n",
    "                                    result['dynamics'] = dynamics\n",
    "                                    \n",
    "                        # sliceTimingVector\n",
    "                        if child2.tag == 'sliceTimingVector':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    sliceTimingVector = child3.text\n",
    "                                    result['sliceTimingVector'] = sliceTimingVector\n",
    "                                    \n",
    "                        # nb_slices\n",
    "                        if child2.tag == 'nb_slices':\n",
    "                            for child3 in child2:\n",
    "                                if child3.tag == 'value':\n",
    "                                    nb_slices = child3.text\n",
    "                                    result['nb_slices'] = nb_slices\n",
    "                \n",
    "        \n",
    "    except:\n",
    "        print 'exception'\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n",
      "{'sliceTimingVector': '1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30', 'dynamics': '240', 'nb_slices': '31', 'TR': '2', 'epidir': '/EPIBOLD/'}\n"
     ]
    }
   ],
   "source": [
    "epiResults = getEpiInfos(xmlfile)\n",
    "print epiResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getT1file(xmlfile):\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        # T1 directory and file\n",
    "        for t1 in root.iter('T1'):\n",
    "            for child in t1:\n",
    "                #print child.text\n",
    "                if child.tag == 'file':\n",
    "                    t1 = child.text\n",
    "                    t1 = flibasedir + t1\n",
    "                    # print  t1\n",
    "    except:\n",
    "        print 'exception'\n",
    "    return t1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/T1/t0009_t1_s03.nii\n"
     ]
    }
   ],
   "source": [
    "t1 = getT1file(xmlfile)\n",
    "print t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pileline declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - first node data grabbing by select files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EPIBOLD/\n",
      "/EPIBOLD/\n",
      "bold-dataset\n",
      "\n",
      "     \n",
      "parameters\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'T1': <undefined>, 'epi': <undefined>}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epidir = getEpiInfos(xmlfile)['epidir']\n",
    "epidir = flibasedir + epidir\n",
    "\n",
    "from nipype import SelectFiles, Node\n",
    "templates = dict(T1=t1,\n",
    "                 epi= epidir + \"/\" + \"*.nii\")\n",
    "\n",
    "filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "filesource.inputs.subject_id = \"subj1\"\n",
    "filesource.outputs.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - segment T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segment = pe.Node(interface=spm.NewSegment(), name='segment')\n",
    "\n",
    "#seg.inputs.channel_files = 't0009_t1_s03.nii'\n",
    "segment.inputs.channel_info =(0.001,60.0,(True,True))          \n",
    "segment.inputs.sampling_distance= 3.0\n",
    "# todo donner un chemin de TPM.nii comme argument de la future fct\n",
    "tissue1 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 1), 1, (True,False), (False, False))\n",
    "tissue2 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 2), 1, (True,False), (False, False))\n",
    "tissue3 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 3), 2, (True,False), (False, False))\n",
    "tissue4 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 4), 3, (True,False), (False, False))\n",
    "tissue5 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 5), 4, (True,False), (False, False))\n",
    "tissue6 = (('/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii', 6), 2, (False,False), (False, False))\n",
    "segment.inputs.tissues = [tissue1, tissue2, tissue3, tissue4, tissue5, tissue6]\n",
    "segment.inputs.affine_regularization = 'mni'\n",
    "#segment.inputs.warping_regularization = [0.0, 0.001, 0.5, 0.05, 0.2]\n",
    "segment.inputs.write_deformation_fields = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - slice timing of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]\n"
     ]
    }
   ],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.spm import SliceTiming\n",
    "\n",
    "st = pe.Node(interface=spm.SliceTiming(), name='st')\n",
    "#st.inputs.in_files = 'functional.nii'\n",
    "st.inputs.num_slices = int(epiResults['nb_slices'])\n",
    "st.inputs.time_repetition = float(epiResults['TR'])\n",
    "st.inputs.time_acquisition = float(epiResults['TR']) - float(epiResults['TR'])/2.0\n",
    "st.inputs.slice_order = lint\n",
    "st.inputs.ref_slice = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - realign of epibold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realign = pe.Node(interface=spm.Realign(), name='realign')\n",
    "\n",
    "realign.inputs.register_to_mean = False\n",
    "realign.inputs.quality = 0.9\n",
    "realign.inputs.separation = 4\n",
    "realign.inputs.fwhm = 5\n",
    "realign.inputs.interp = 2\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "# essai au defaut 2, 1 realign.inputs.write_which = [0, 1]\n",
    "realign.inputs.write_which = [2, 1]\n",
    "realign.inputs.write_interp = 4\n",
    "realign.inputs.wrap = [0, 0, 0]\n",
    "realign.inputs.write_mask = True\n",
    "realign.inputs.out_prefix = 'r'\n",
    "realign.inputs.jobtype = 'write'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spm.Coregister()\n",
    "coregister = pe.Node(interface=spm.Coregister(), name='coregister' )\n",
    "\n",
    "coregister.inputs.cost_function = 'nmi'\n",
    "coregister.inputs.separation = [4.0, 2.0]\n",
    "coregister.inputs.jobtype = 'write'\n",
    "coregister.inputs.tolerance = [0.02, 0.02, 0.02, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]\n",
    "coregister.inputs.fwhm = [7.0, 7.0]\n",
    "coregister.inputs.write_interp = 4\n",
    "coregister.inputs.write_wrap = [0, 0, 0]\n",
    "coregister.inputs.write_mask = False \n",
    "coregister.inputs.out_prefix = 'c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# passage à normalize sans 12 non on repasse en 12 et on prend des param de pierre y\n",
    "norm12 = pe.Node(interface=spm.Normalize12(), name='norm12')\n",
    "\n",
    "norm12.inputs.bias_regularization = 0.0001\n",
    "norm12.inputs.bias_fwhm = 60\n",
    "# todo putthis parameter in args of a fct\n",
    "# norm12.inputs.tpm = '/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM.nii'\n",
    "norm12.inputs.affine_regularization_type = 'mni'\n",
    "norm12.inputs.sampling_distance = 3.0\n",
    "norm12.inputs.write_bounding_box = [[-90.0, -126.0, -72.0],[ 90.0, 90.0, 108.0]]\n",
    "norm12.inputs.write_voxel_sizes = [2.0, 2.0, 2.0]\n",
    "norm12.inputs.write_interp = 4\n",
    "norm12.inputs.jobtype = 'write'\n",
    "norm12.inputs.use_v8struct = True\n",
    "#norm12.inputs.out_prefix = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connection du pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect(filesource,\"T1\" ,segment, 'channel_files')\n",
    "\n",
    "preproc.connect(filesource,\"epi\" ,st, 'in_files')\n",
    "\n",
    "preproc.connect(st,\"timecorrected_files\" ,realign, 'in_files')\n",
    "\n",
    "preproc.connect(filesource,\"T1\" ,coregister, 'source')\n",
    "preproc.connect(realign,\"mean_image\" ,coregister, 'target')\n",
    "preproc.connect(realign,\"realigned_files\" ,coregister, 'apply_to_files')\n",
    "\n",
    "preproc.connect(segment,\"forward_deformation_field\" ,norm12, \"deformation_file\")\n",
    "preproc.connect(coregister,\"coregistered_files\" ,norm12, 'apply_to_files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the results in the datasink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment results\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n",
    "preproc.connect(segment,  'bias_field_images' , datasink, 'structural.@par1')\n",
    "preproc.connect(segment,  'forward_deformation_field' , datasink, 'structural.@par2')\n",
    "preproc.connect(segment,  'inverse_deformation_field' , datasink, 'structural.@par3')\n",
    "preproc.connect(segment,  'modulated_class_images' , datasink, 'structural.@par4')\n",
    "preproc.connect(segment,  'native_class_images' , datasink, 'structural.@par5')\n",
    "preproc.connect(segment,  'transformation_mat' , datasink, 'structural.@par6')\n",
    "preproc.connect(segment,  'dartel_input_images' , datasink, 'structural.@par7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice timing results\n",
    "preproc.connect(st,  'timecorrected_files', datasink, 'functionnal')\n",
    "\n",
    "# realign mean_image and realignment_parameters\n",
    "preproc.connect(realign,  'mean_image', datasink, 'functionnal.@par')\n",
    "preproc.connect(realign,  'realignment_parameters', datasink, 'functionnal.@par1')\n",
    "preproc.connect(realign,  'realigned_files', datasink, 'functionnal.@par2')\n",
    "preproc.connect(coregister,  'coregistered_files', datasink, 'functionnal.@par3')\n",
    "\n",
    "preproc.connect(norm12,  'normalized_files', datasink, 'functionnal.@par4')\n",
    "preproc.connect(norm12,  'normalized_image', datasink, 'functionnal.@par5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node filesource in dir: /tmp/tmpPZPcym/preproc/filesource\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node segment in dir: /tmp/tmpgdH0jp/preproc/segment\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node st in dir: /tmp/tmp1Tvh7D/preproc/st\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node realign in dir: /tmp/tmp05HFQE/preproc/realign\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node coregister in dir: /tmp/tmpJrvsM8/preproc/coregister\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node norm12 in dir: /tmp/tmpGnJrkm/preproc/norm12\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n",
      "INFO:workflow:Executing node datasink in dir: /tmp/tmp72GjvE/preproc/datasink\n",
      "INFO:workflow:Runtime memory and threads stats unavailable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fa92ce02c10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uses SPM12's new Normalise routine for warping an image to a template.\n",
      "Spatial normalisation is now done via the segmentation routine (which was\n",
      "known as ``New Segment`` in SPM8). Note that the normalisation in SPM12\n",
      "is done towards a file containing multiple tissue probability maps, which\n",
      "was not the cass in SPM8.\n",
      "\n",
      "http://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf#page=49\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import nipype.interfaces.spm as spm\n",
      ">>> norm12 = spm.Normalize12()\n",
      ">>> norm12.inputs.image_to_align = 'structural.nii'\n",
      ">>> norm12.inputs.apply_to_files = 'functional.nii'\n",
      ">>> norm12.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "\t[Mandatory]\n",
      "\tdeformation_file: (a file name)\n",
      "\t\tfile y_*.nii containing 3 deformation fields for the deformation in\n",
      "\t\tx, y and z dimension\n",
      "\t\tmutually_exclusive: image_to_align, tpm\n",
      "\timage_to_align: (an existing file name)\n",
      "\t\tfile to estimate normalization parameters with\n",
      "\t\tmutually_exclusive: deformation_file\n",
      "\n",
      "\t[Optional]\n",
      "\taffine_regularization_type: ('mni' or 'size' or 'none')\n",
      "\t\tmni, size, none\n",
      "\tapply_to_files: (a list of items which are an existing file name or a\n",
      "\t\t list of items which are an existing file name)\n",
      "\t\tfiles to apply transformation to\n",
      "\tbias_fwhm: (30 or 40 or 50 or 60 or 70 or 80 or 90 or 100 or 110 or\n",
      "\t\t 120 or 130 or 140 or 150 or 'Inf')\n",
      "\t\tFWHM of Gaussian smoothness of bias\n",
      "\tbias_regularization: (0 or 1e-05 or 0.0001 or 0.001 or 0.01 or 0.1 or\n",
      "\t\t 1 or 10)\n",
      "\t\tno(0) - extremely heavy (10)\n",
      "\tignore_exception: (a boolean, nipype default value: False)\n",
      "\t\tPrint an error message instead of throwing an exception in case the\n",
      "\t\tinterface fails to run\n",
      "\tjobtype: ('estwrite' or 'est' or 'write', nipype default value:\n",
      "\t\t estwrite)\n",
      "\t\tEstimate, Write or do Both\n",
      "\tmatlab_cmd: (a string)\n",
      "\t\tmatlab command to use\n",
      "\tmfile: (a boolean, nipype default value: True)\n",
      "\t\tRun m-code using m-file\n",
      "\tpaths: (a list of items which are a directory name)\n",
      "\t\tPaths to add to matlabpath\n",
      "\tsampling_distance: (a float)\n",
      "\t\tSampling distance on data for parameter estimation\n",
      "\tsmoothness: (a float)\n",
      "\t\tvalue (in mm) to smooth the data before normalization\n",
      "\ttpm: (an existing file name)\n",
      "\t\ttemplate in form of tissue probablitiy maps to normalize to\n",
      "\t\tmutually_exclusive: deformation_file\n",
      "\tuse_mcr: (a boolean)\n",
      "\t\tRun m-code using SPM MCR\n",
      "\tuse_v8struct: (a boolean, nipype default value: True)\n",
      "\t\tGenerate SPM8 and higher compatible jobs\n",
      "\twarping_regularization: (a list of from 5 to 5 items which are a\n",
      "\t\t float)\n",
      "\t\tcontrols balance between parameters and data\n",
      "\twrite_bounding_box: (a list of from 2 to 2 items which are a list of\n",
      "\t\t from 3 to 3 items which are a float)\n",
      "\t\t3x2-element list of lists representing the bounding box (in mm) to\n",
      "\t\tbe written\n",
      "\twrite_interp: (0 <= an integer <= 7)\n",
      "\t\tdegree of b-spline used for interpolation\n",
      "\twrite_voxel_sizes: (a list of from 3 to 3 items which are a float)\n",
      "\t\t3-element list representing the voxel sizes (in mm) of the written\n",
      "\t\tnormalised images\n",
      "\n",
      "Outputs::\n",
      "\n",
      "\tdeformation_field: (a list of items which are an existing file name)\n",
      "\t\tNIfTI file containing 3 deformation fields for the deformation in x,\n",
      "\t\ty and z dimension\n",
      "\tnormalized_files: (a list of items which are an existing file name)\n",
      "\t\tNormalized other files\n",
      "\tnormalized_image: (a list of items which are an existing file name)\n",
      "\t\tNormalized file that needed to be aligned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spm.Normalize12().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Coregister.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.Realign().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = epiResults['sliceTimingVector'].split()\n",
    "lint =[]\n",
    "for i in l:\n",
    "    lint.append(int(i))\n",
    "print lint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(epiResults['TR']) - float(epiResults['TR'])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.SliceTiming().input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_corrected_images = <undefined>\n",
    "bias_field_images = <undefined>\n",
    "dartel_input_images = <undefined>\n",
    "forward_deformation_field = <undefined>\n",
    "inverse_deformation_field = <undefined>\n",
    "modulated_class_images = <undefined>\n",
    "native_class_images = <undefined>\n",
    "normalized_class_images = <undefined>\n",
    "transformation_mat = <undefined>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#advanced way to connect multiple nodes\n",
    "workflowname.connect([(nodename1, nodename2, [('output_node1', 'input_node2')]),\n",
    "                      (nodename1, nodename3, [('output_node1', 'input1_node3')]),\n",
    "                      (nodename2, nodename3, [('output1_node2', 'input1_node3'),\n",
    "                                              ('output2_node2', 'input2_node3')\n",
    "                                              ])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.connect([(filesource, segment, [('T1', 'channel_files')]),\n",
    "                      (segment, datasink, [('normalized_class_images', 'normalized'),\n",
    "                                              ('bias_corrected_images', 'bias_corrected')\n",
    "                                              ])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = '/homes_unix/hirsch/_pypipe/datadir/data_results'\n",
    "preproc.connect(segment,  'normalized_class_images', datasink, 'structural')\n",
    "preproc.connect(segment,  'bias_corrected_images' , datasink, 'structural.@par')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.input_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spm.NewSegment.output_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/Atlases/TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Where should the output data be stored at?\n",
    "sink = nipype.DataSink()\n",
    "sink.inputs.base_directory = experiment_dir + '/output_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd /homes_unix/hirsch/_pypipe/datadir/data_set/t0009/repos01/EPIBOLD\n",
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
