{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essai pour avoir un iterable lisibles pas tout le nom du fichier dans la prochaine cellule on aura le code copié depuis wing et modifié...\n",
    "on se racroche aux étapes précédentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python \n",
    "# coding: utf-8\n",
    "\n",
    "import ginfizz_config\n",
    "\n",
    "# cette version est faite pour traiter le signal bp sans arima\n",
    "\n",
    "# nouvelles specs on part d'un nouvel atlas de 10 régions et on voit quels sont les voxels qui sont en correlations avec ces régions  <br> \n",
    "# on va d'abord determiner combien il y de regions, puis on va les calculer à partir de l'atlas utilisateur\n",
    "\n",
    "\n",
    "def identifyRegionAtlases(atlas_file):\n",
    "        \"\"\"compute Regions of Interest number, their integer values from atlas file given by the user,\n",
    "        then compute the atlas image for each of n values, then\n",
    "        output is the array of regions atlases, each one representing a different ROI \"\"\"\n",
    "\n",
    "        import numpy as np     \n",
    "        import nibabel as nib     \n",
    "        import os \n",
    "\n",
    "        #------------------------------\n",
    "        # fcts used by current function\n",
    "        #------------------------------\n",
    "\n",
    "        #    \n",
    "        def selectRegion(atlas_file, n):\n",
    "                ''' lets select region i input is atlasFile, output is maskFile with region n  '''\n",
    "\n",
    "                atlas_img=nib.load(atlas_file)         \n",
    "                atlas_array=np.asarray(atlas_img.dataobj).copy() # Avoid caching the proxy image\n",
    "                region_array = atlas_array\n",
    "                # binary mask the resulting image\n",
    "                region_array[atlas_array <> n] = 0\n",
    "                region_array[atlas_array == n] = 1\n",
    "                region_image = nib.Nifti1Image(region_array, atlas_img.affine, atlas_img.header)\n",
    "                result = os.getcwd() + '/' + 'region_image' + str(n) + '.nii'\n",
    "                nib.save(region_image, result)\n",
    "                return result   \n",
    "\n",
    "        def identifyRegionNb(atlas_file):\n",
    "                \"\"\"compute Regions of Interest number, their integer values from atlas file given by the user, \n",
    "                output is the array of int number, each one representing a different ROI \"\"\"\n",
    "\n",
    "                atlas_img=nib.load(atlas_file)         \n",
    "                atlas_array=np.asarray(atlas_img.dataobj).copy() # Avoid caching the proxy image\n",
    "                atlas_array = atlas_array[atlas_array>0]\n",
    "                # np.unique(a)\n",
    "                regions = np.unique(atlas_array)\n",
    "                print regions\n",
    "                regionsNb = len(regions) \n",
    "                return regions\n",
    "\n",
    "\n",
    "        #------------------------------\n",
    "        # end fcts used by current function\n",
    "        #------------------------------    \n",
    "\n",
    "        roi_img_list =[]\n",
    "        roi_nbs = identifyRegionNb(atlas_file)\n",
    "        for i in roi_nbs:\n",
    "\n",
    "                roi_img_list.append(selectRegion(atlas_file, i))\n",
    "\n",
    "        return roi_img_list\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "#atlas_file = '/scratch/user/hirsch/datadir/data_set/t0009/repos01/Atlases/atlas_2reg.nii'\n",
    "\n",
    "#regions_images_list = identifyRegionAtlases(atlas_file)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "def aicha(roiatlasfile, resultdir):\n",
    "# # Start Pileline -> declaration\n",
    "        \n",
    "        import nipype.interfaces.io as nio           # Data i/o\n",
    "        import nipype.interfaces.spm as spm          # spm\n",
    "        import nipype.interfaces.matlab as mlab      # how to run matlab\n",
    "        import nipype.interfaces.utility as util     # utility\n",
    "        import nipype.pipeline.engine as pe          # pypeline engine\n",
    "        \n",
    "        from nipype.interfaces.utility import Function, IdentityInterface\n",
    "        \n",
    "        from nipype.interfaces.fsl.maths import MathsCommand\n",
    "        from nipype.interfaces.fsl.utils import PlotMotionParams   # to plot moco variabl\n",
    "        from nipype import Node, MapNode        \n",
    "\n",
    "        # creation of a subworflow to process ROI Correlations\n",
    "        connectivity = pe.Workflow(name='connectivity')\n",
    "        \n",
    "        # ## logging management \n",
    "        \n",
    "        from nipype import config\n",
    "        cfg = dict(logging=dict(workflow_level = 'DEBUG'),\n",
    "               execution={'stop_on_first_crash': False,\n",
    "                          'hash_method': 'content'})\n",
    "        config.update_config(cfg)\n",
    "        connectivity.config['execution'] = {'stop_on_first_rerun': 'False',\n",
    "                                   'hash_method': 'timestamp'}\n",
    "        \n",
    "        # create logging dir done in main resultdir os.path.join('dir','other-dir') os.makedirs(newpath)\n",
    "        import os\n",
    "        logsdir = os.path.join(resultdir, 'logs')\n",
    "        \n",
    "        from nipype import config, logging\n",
    "        config.update_config({'logging': {'log_directory': logsdir,\n",
    "                                      'log_to_file': True }})\n",
    "        logging.update_logging(config)\n",
    "        \n",
    "        from nipype import logging\n",
    "        iflogger = logging.getLogger('interface')\n",
    "        message = \"Start of aicha workflow\"\n",
    "        iflogger.info(message)        \n",
    "        \n",
    "        # 0 - we fix the working dir to get the commands later\n",
    "        \n",
    "        working_dir =  os.path.join(resultdir, \"_report\")\n",
    "        connectivity.base_dir = working_dir\n",
    "               \n",
    "        # ## 1 - first node data grabbing by select files \n",
    "        \n",
    "\n",
    "\n",
    "        # comprendre bp dir \n",
    "        #arimadir = '/scratch/user/hirsch/datadir4/data_results_py/functionnal/bandpassedFile'\n",
    "        \n",
    "        #resultdir = '/scratch/user/hirsch/datadir4/data_results_py/'\n",
    "                \n",
    "        #from nipype import SelectFiles, Node\n",
    "        #templates = dict(arimaFile=arimadir+ \"/\" + \"*.nii.gz\",\n",
    "                         #normalized_c1_file=resultdir+ \"/\" + \"structural/normalized_files/wc1*.nii\",\n",
    "                         #normalized_c2_file=resultdir+ \"/\" + \"structural/normalized_files/wc2*.nii\")\n",
    "        \n",
    "        #filesource = Node(SelectFiles(templates), \"filesource\")\n",
    "        #filesource.inputs.subject_id = \"subj1\"\n",
    "        #filesource.outputs.get()\n",
    "        \n",
    "        # intput node\n",
    "        field_list=['normalized_masks', \n",
    "                     'bandpassedFile']\n",
    "\n",
    "\n",
    "        inputNodeAicha = Node(IdentityInterface(fields=field_list), name=\"inputNodeAicha\")        \n",
    "        \n",
    "        \n",
    "        # lets compute the brain mask c1 + c2 threshold at 0.2 to compute later the target time courses\n",
    "        def regexfilter(files_list,patern):\n",
    "                import re\n",
    "        \n",
    "                for f in files_list:\n",
    "                        if re.search(patern, str(f)):\n",
    "                                res = f         \n",
    "                return res                    \n",
    "        \n",
    "        from nipype.interfaces.fsl import MultiImageMaths\n",
    "        \n",
    "        addFiles = pe.Node(interface=MultiImageMaths(), name='addFiles')\n",
    "        \n",
    "        addFiles.inputs.op_string = \"-add %s\"   \n",
    "        addFiles.inputs.output_datatype = 'short'\n",
    "        addFiles.inputs.ignore_exception = False     \n",
    "        addFiles.inputs.output_type = 'NIFTI'     \n",
    "        addFiles.inputs.terminal_output = 'stream'     \n",
    "        \n",
    "        connectivity.connect(inputNodeAicha,('normalized_masks',regexfilter,r'wc1.*nii'), addFiles, \"in_file\")\n",
    "        connectivity.connect(inputNodeAicha,('normalized_masks',regexfilter,r'wc2.*nii') , addFiles, \"operand_files\")\n",
    "        \n",
    "        from nipype.interfaces.fsl import Threshold\n",
    "        \n",
    "        thrFile = pe.Node(interface=Threshold(), name='thrFile')\n",
    "        \n",
    "        thrFile.inputs.thresh = 0.2   \n",
    "        thrFile.inputs.ignore_exception = False     \n",
    "        thrFile.inputs.output_type = 'NIFTI'     \n",
    "        thrFile.inputs.terminal_output = 'stream'     \n",
    "        \n",
    "        connectivity.connect(addFiles,\"out_file\" , thrFile, \"in_file\")\n",
    "        \n",
    "        # ------------------------------------------------------------\n",
    "        # first lets identify all the region of Interest ROIs\n",
    "        regions_images_list = identifyRegionAtlases(roiatlasfile)\n",
    "        print regions_images_list\n",
    "        \n",
    "        # here comes the node with iterables, we have to iterate the treatment for each region identified by previous step\n",
    "        # b = pe.MapNode(interface=B(), name=\"b\", iterfield=['in_file']) \n",
    "        # http://nipype.readthedocs.io/en/latest/users/mapnode_and_iterables.html\n",
    "        \n",
    "        # lets calculate the mean residu signal eg. time courses in every region \n",
    "        # lets use iterables -> startnode.iterables = ('subject_id', subjects)\n",
    "        \n",
    "        from nipype.interfaces.fsl.utils import ImageMeants\n",
    "        \n",
    "        regMeants = Node(ImageMeants(), name=\"regMeants\")  \n",
    "        \n",
    "        regMeants.iterables = ('mask', regions_images_list)\n",
    "        \n",
    "        regMeants.inputs.ignore_exception = False     \n",
    "        regMeants.inputs.order = 1     \n",
    "        regMeants.inputs.output_type = 'NIFTI_GZ'     \n",
    "        regMeants.inputs.terminal_output = 'stream'     \n",
    "        connectivity.connect(inputNodeAicha, \"bandpassedFile\" , regMeants, \"in_file\")   \n",
    "        \n",
    "        \n",
    "        # correlation computations\n",
    "        def computeCorrelations(residus, residusRegMean, brainMask):\n",
    "            \n",
    "                '''Function that takes 3 parameters\n",
    "                   residus: the residu of arima time courses\n",
    "                   residuRegMean: the residus mean on determined region i\n",
    "                   if ARIMA is not triggered the residus is the bandpassed signal\n",
    "                   and residuregMean is the average signal on each ROI\n",
    "                   brainMask: the mask of gm and wm thresholded at 0,2\n",
    "                   Computes pearson correlations between the seed eg. residuRegMean\n",
    "                   and all the voxels of the brainMask\n",
    "                   Returns an Nifti images containing the correlations'''\n",
    "                \n",
    "                import os\n",
    "                import numpy as np\n",
    "                import matplotlib.pyplot as plt\n",
    "                import nibabel as nib\n",
    "                from scipy.stats.stats import pearsonr\n",
    "                \n",
    "                # first we get the seed mean signal\n",
    "                seed_ts_array = np.loadtxt(residusRegMean)\n",
    "                \n",
    "                # from an other hand we get the residus 4D matrix\n",
    "                fmri_data=nib.load(residus) \n",
    "                fmri_array=np.asarray(fmri_data.dataobj)\n",
    "                \n",
    "                # we get the coordinnates of voxels in all gm and wm normalized todo \n",
    "                reg_data=nib.load(brainMask) \n",
    "                regarray=np.asarray(reg_data.dataobj)\n",
    "                # transpose(nonzero(a))\n",
    "                reg_coords = np.transpose(np.nonzero(regarray))\n",
    "                volume_shape = reg_coords.shape\n",
    "                print volume_shape\n",
    "                coords = list(np.ndindex(volume_shape))\n",
    "                print len(coords)\n",
    "                \n",
    "                # the we iterate the correlation calculation on all voxels of the brain mask\n",
    "            \n",
    "                # the correlation matrix is initialized with all values to 0 \n",
    "                corr_matrix = np.full(reg_data.shape, 0, dtype=float)\n",
    "            \n",
    "                for i in range(reg_coords.shape[0]):\n",
    "                    target_array = fmri_array[reg_coords[i, 0], reg_coords[i, 1],reg_coords[i,2], :]\n",
    "                    #print target_array\n",
    "                    non_zero_nb = np.count_nonzero(target_array)\n",
    "                    \n",
    "                    # if target time courses are all null, we do not compute correlation\n",
    "                    if non_zero_nb:\n",
    "                        try:\n",
    "                            p = pearsonr(seed_ts_array,target_array) \n",
    "                            corr_matrix[reg_coords[i, 0], reg_coords[i, 1],reg_coords[i,2]] = p[0] \n",
    "                        except:\n",
    "                            iflogger.info(\"exception calculating pearson correlation\") \n",
    "                \n",
    "                # save matrix in a file\n",
    "                # create the resulting image\n",
    "                corr_image = nib.Nifti1Image(corr_matrix,affine=reg_data.affine, header=reg_data.header)\n",
    "                # save the correlation array\n",
    "                out_file = os.getcwd() + '/' + 'corr_roi_reg.nii'\n",
    "                nib.save(corr_image, out_file)\n",
    "                \n",
    "                return out_file\n",
    "                \n",
    "        # node to compute the correlation matrix as each region i of user atlas mean signal serves as a seed \n",
    "        # and brain mask signal residuserves as the targets\n",
    "        # def computeCorrelations(residus, residusRegMean, brainMask):\n",
    "        correlationsComputeNode = Node(Function(input_names=['residus', 'residusRegMean', 'brainMask'],\n",
    "                                        output_names=['out_file'],\n",
    "                                        function=computeCorrelations),\n",
    "                                        name='correlationsComputeNode')\n",
    "        \n",
    "        connectivity.connect(inputNodeAicha, \"bandpassedFile\", correlationsComputeNode, \"residus\")\n",
    "        connectivity.connect(regMeants, \"out_file\", correlationsComputeNode, \"residusRegMean\")\n",
    "        connectivity.connect(thrFile, \"out_file\", correlationsComputeNode, \"brainMask\")\n",
    "        \n",
    "        # data sink\n",
    "        datasink = pe.Node(nio.DataSink(), name='datasink')\n",
    "        datasink.inputs.base_directory = resultdir\n",
    "        \n",
    "        # data sink brain mask to compute target time courses\n",
    "        connectivity.connect(thrFile, \"out_file\", datasink, 'structural.normalized_c1c2_file')\n",
    "        \n",
    "        # data sink of mean signal on ROIs that will be used as seed signal\n",
    "        connectivity.connect(regMeants,  'out_file', datasink, 'functionnal.regMeants')\n",
    "        \n",
    "        # data sink of correlations matrix for ROI i\n",
    "        connectivity.connect(correlationsComputeNode,  'out_file', datasink, 'functionnal.correlationMatrix')\n",
    "        \n",
    "        return connectivity\n",
    "        #connectivity.run()\n",
    "\n",
    "\n",
    "        # # end of pipe\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
